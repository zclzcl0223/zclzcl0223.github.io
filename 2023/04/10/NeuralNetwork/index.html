<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zclzcl0223.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12,"onmobile":false},"hljswrap":true,"copycode":{"enable":true,"style":"mac","show_result":false},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Neural network, which is also called artificial neural networks (ANNs) or neural networks (NNs) is an advanced model in machine learning. This post includes the course notes of neural network course b">
<meta property="og:type" content="article">
<meta property="og:title" content="Neural Network">
<meta property="og:url" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/index.html">
<meta property="og:site_name" content="JourneyToCoding">
<meta property="og:description" content="Neural network, which is also called artificial neural networks (ANNs) or neural networks (NNs) is an advanced model in machine learning. This post includes the course notes of neural network course b">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/1.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/2.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/3.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/4.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/5.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/6.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/7.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/8.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/9.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/10.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/11.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/12.png">
<meta property="article:published_time" content="2023-04-10T13:30:44.000Z">
<meta property="article:modified_time" content="2023-08-09T05:56:12.000Z">
<meta property="article:author" content="Chaolv Zeng">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/1.png">


<link rel="canonical" href="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/","path":"2023/04/10/NeuralNetwork/","title":"Neural Network"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Neural Network | JourneyToCoding</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <a target="_blank" rel="noopener" href="https://github.com/zclzcl0223" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">JourneyToCoding</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Code for Fun</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Component"><span class="nav-number">2.</span> <span class="nav-text">Component</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Layer"><span class="nav-number">2.1.</span> <span class="nav-text">Layer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Neuron"><span class="nav-number">2.2.</span> <span class="nav-text">Neuron</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Notation"><span class="nav-number">2.3.</span> <span class="nav-text">Notation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Forward-propagation-algorithm"><span class="nav-number">3.</span> <span class="nav-text">Forward propagation algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Numpy-and-Tensorflow"><span class="nav-number">3.1.</span> <span class="nav-text">Numpy and Tensorflow</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Vectorization"><span class="nav-number">4.</span> <span class="nav-text">Vectorization</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Activation-function"><span class="nav-number">5.</span> <span class="nav-text">Activation function</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-function"><span class="nav-number">5.1.</span> <span class="nav-text">Linear function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sigmoid"><span class="nav-number">5.2.</span> <span class="nav-text">Sigmoid</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ReLU"><span class="nav-number">5.3.</span> <span class="nav-text">ReLU</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Softmax-regression"><span class="nav-number">6.</span> <span class="nav-text">Softmax regression</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Multi-label-classification"><span class="nav-number">7.</span> <span class="nav-text">Multi-label classification</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adam-algorithm"><span class="nav-number">8.</span> <span class="nav-text">Adam algorithm</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Chaolv Zeng"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Chaolv Zeng</p>
  <div class="site-description" itemprop="description">Start of Something New</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">102</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zclzcl0223" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zclzcl0223" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chaostsang0223@gmail.com" title="E-Mail → mailto:chaostsang0223@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="sidebar-inner sidebar-post-related">
          <div class="animated">
              <div class="links-of-blogroll-title"><i class="fa fa-signs-post fa-fw"></i>
    Related Posts
  </div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/04/12/Tensorflow/" rel="bookmark">
        <time class="popular-posts-time">2023-04-12</time>
        <br>
      Tensorflow
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/05/07/NumericalStability/" rel="bookmark">
        <time class="popular-posts-time">2023-05-07</time>
        <br>
      Numerical Stability
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/04/05/SupervisedLearning/" rel="bookmark">
        <time class="popular-posts-time">2023-04-05</time>
        <br>
      Supervised Learning
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/05/14/CommonCNNModels/" rel="bookmark">
        <time class="popular-posts-time">2023-05-14</time>
        <br>
      Common CNN Models
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/04/23/LabsOfMachineLearningByAndrewNg2/" rel="bookmark">
        <time class="popular-posts-time">2023-04-23</time>
        <br>
      Lab: Advanced Learning Algorithms
      </a>
    </li>
  </ul>

          </div>
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zclzcl0223.github.io/2023/04/10/NeuralNetwork/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chaolv Zeng">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JourneyToCoding">
      <meta itemprop="description" content="Start of Something New">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Neural Network | JourneyToCoding">
      <meta itemprop="description" content="Neural network, which is also called artificial neural networks (ANNs) or neural networks (NNs) is an advanced model in machine learning. This post includes the course notes of neural network course by Andrew Ng.">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Neural Network
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-04-10 21:30:44" itemprop="dateCreated datePublished" datetime="2023-04-10T21:30:44+08:00">2023-04-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-08-09 13:56:12" itemprop="dateModified" datetime="2023-08-09T13:56:12+08:00">2023-08-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Machine-Learning-by-AndrewNg/" itemprop="url" rel="index"><span itemprop="name">Machine Learning by AndrewNg</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>5 mins.</span>
    </span>
</div>

            <div class="post-description">Neural network, which is also called artificial neural networks (ANNs) or neural networks (NNs) is an advanced model in machine learning. This post includes the course notes of neural network course by Andrew Ng.</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Neural network, which can also be named <em><strong>deep learning</strong></em>, is an advanced machine learning model.</p>
<blockquote>
<p>Neural network is an algorithm suitable for nearly all kinds of machine learning. Compared to traditional models, neural network performs better when the training set is large.</p>
</blockquote>
<h1 id="Component"><a href="#Component" class="headerlink" title="Component"></a>Component</h1><h2 id="Layer"><a href="#Layer" class="headerlink" title="Layer"></a>Layer</h2><p>Neural network is consisted of different layers. A layer is a grouping of neurons which takes the same or similar features as input and in turn outputs a few numbers together. The <em><strong>first layer</strong></em> (layer 0) is called <em><strong>input layer</strong></em> where input and output are the same. The <em><strong>last layer</strong></em> is called <em><strong>output layer</strong></em> which outputs the value of the neural network. Input and output layer are the only two layers that are visible to us, therefore, the other layers are called <em><strong>hidden layer</strong></em>.</p>
<blockquote>
<p>There are different types of hidden layer:</p>
<ul>
<li>Dense layer: Each neuron output is a function of all the activation outputs of the previous layer;</li>
<li>Convolutional layer: Each neuron only looks at part of the previous layer&#39;s outputs. Different neurons may look at the same outputs.</li>
<li>...</li>
</ul>
</blockquote>
<p><img src="/2023/04/10/NeuralNetwork/1.png" alt="1"></p>
<center style="font-size:12px;font-weight:bold">Fig. 1. Multilayer perceptron</center>

<h2 id="Neuron"><a href="#Neuron" class="headerlink" title="Neuron"></a>Neuron</h2><p>Each layer is made up of several (including one) neurons. Each neuron is a traditional machine learning model, like linear regression, logistic regression and so on. The output of one neuron is called <em><strong>activation</strong></em> and the function of this neuron is called <em><strong>activation function</strong></em>, which means it activate the next neuron.</p>
<p>The magic of neural network is that it can learn new features by itself. So, we do not need to define who is the father of one neuron. Actually, each neuron will take the activations as its input, but the parameter of some activations may be zero. We just need to input the training set and define the structure of neural network. Then, the neural network will produce the most suitable new features. That is, a neuron (traditional model) is actually a new feature.</p>
<blockquote>
<p>The structure of neural network is called <em><strong>neural network architecture</strong></em>. It defines the number of layers and the number of neurons in each layer.</p>
</blockquote>
<p><img src="/2023/04/10/NeuralNetwork/2.png" alt="2"></p>
<center style="font-size:12px;font-weight:bold">Fig. 2.</center>

<h2 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h2><ul>
<li>$a^{[i]}$ &#x3D; output of layer i;</li>
<li>$\vec{w}^{[i]}, b^{[i]}$&#x3D;parameters of layer i.</li>
</ul>
<h1 id="Forward-propagation-algorithm"><a href="#Forward-propagation-algorithm" class="headerlink" title="Forward propagation algorithm"></a>Forward propagation algorithm</h1><p>Forward propagation is a series of steps to count $f$. It is an inference or prediction of $y$. So, it is similar to $\widehat{y}$ in traditional model.</p>
<p><img src="/2023/04/10/NeuralNetwork/3.png" alt="3"></p>
<center style="font-size:12px;font-weight:bold">Fig. 3. Handwritten digit recognition</center>

<h2 id="Numpy-and-Tensorflow"><a href="#Numpy-and-Tensorflow" class="headerlink" title="Numpy and Tensorflow"></a>Numpy and Tensorflow</h2><p>The data representation in numpy is slightly different from tensorflow. In numpy, we can represent data either in the form of matrix or in the form of vector:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.array([[<span class="number">200</span>, <span class="number">17</span>]]) <span class="comment"># array 1*2</span></span><br><span class="line">x = np.array([[<span class="number">200</span>],[<span class="number">17</span>]]) <span class="comment"># array 2*1</span></span><br><span class="line">x = np.array([<span class="number">200</span>, <span class="number">17</span>]) <span class="comment"># just a row vector</span></span><br></pre></td></tr></table></figure>
<p>But we can only represent data in the form of matrix in tensorflow. Therefore, when using numpy and tensorflow together, it is advisable to store the data in the form of matrix.</p>
<p>The followings are the implementation of a neuron network about coffee roasting using numpy and tensorflow. (Assuming the neural network has been trained)</p>
<p><img src="/2023/04/10/NeuralNetwork/4.png" alt="4"></p>
<center style="font-size:12px;font-weight:bold">Fig. 4. Coffee roasting (two inputs)</center><br>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">200.0</span>, <span class="number">17.0</span>]])</span><br><span class="line">layer_1 = Dense(units=<span class="number">3</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">a1 = layer_1(x)</span><br><span class="line"></span><br><span class="line">layer_2 = Dense(units=<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">a2 = layer_2(a1)</span><br></pre></td></tr></table></figure>
<p>The data type of <code>a1</code> and <code>a2</code> are tensor,which is a built-in type in tensorflow :</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">When print a1: </span><br><span class="line">tf.Tensor([[0.2 0.7 0.3]], shape=(1, 3), dtype=float32)</span><br></pre></td></tr></table></figure>
<p>We can also print it in the form of numpy:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">When print a1.numpy():</span><br><span class="line">array([0.2, 0.7, 0.3], dtype=float32)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>The difference between tensor and array is that tensor has shape and data while array just has data. Therefore, a tensor variable can actually be treated as an <em>image</em>. That is why tensor data can be processed in GPU.</p>
</blockquote>
<p>Instead of building a neural network layer by layer, we can directly concatenate the layers to form the neural network. That is what <code>Sequential</code> do:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line">model = Sequential([Dense(units=<span class="number">3</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>), Dense(units=<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)])</span><br><span class="line">...</span><br><span class="line">model.predict(x)</span><br></pre></td></tr></table></figure>

<h1 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h1><p>GPU and some CPU functions are very good at doing large matrix multiplications. Neural network can be vectorized, because of which neural network can be processed rapidly.</p>
<p>For layer 1 in the neural network of fig.3, the vectorized version is:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.array([[<span class="number">200</span>, <span class="number">17</span>]])</span><br><span class="line">W = np.array([[<span class="number">1</span>, -<span class="number">3</span>, <span class="number">5</span>], [-<span class="number">2</span>, <span class="number">4</span>, -<span class="number">6</span>]])</span><br><span class="line">B = np.array([[-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dense</span>(<span class="params">A_in, W, B</span>) :</span><br><span class="line">    Z = np.matmul(A_in, W) + B</span><br><span class="line">    A_out = g(Z)  <span class="comment"># A_out is a row vector</span></span><br><span class="line">    <span class="keyword">return</span> A_out</span><br></pre></td></tr></table></figure>

<h1 id="Activation-function"><a href="#Activation-function" class="headerlink" title="Activation function"></a>Activation function</h1><p>Activation function is actually a reprocessing of the model $f$ and creates <strong>a new model</strong>. By using activation function, we can divide our model into two parts. The first part is <strong>uniform</strong> for all models:<br>$$z&#x3D;\vec{w}\cdot\vec{x}+b$$<br>To generate different models, we only need to select the most suitable activation function $g(z)$. And that is the second part. There are three commonly used activation functions: linear function (identity), Sigmoid (soft step) and ReLU (rectified linear unit).</p>
<h2 id="Linear-function"><a href="#Linear-function" class="headerlink" title="Linear function"></a>Linear function</h2><p><img src="/2023/04/10/NeuralNetwork/5.png" alt="5"></p>
<center style="font-size:12px;font-weight:bold">Fig. 5. Linear function</center><br>

<p>In linear function, we do not do anything to the first part of the model. Therefore, our model is just a linear regression model:<br>$$f&#x3D;g(z)&#x3D;\vec{w}\cdot\vec{x}+b$$<br>Since the linear function of a linear function is still a linear function, we actually do not use linear function in the hidden layer, otherwise, the hidden layer will be useless.</p>
<h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><p><img src="/2023/04/10/NeuralNetwork/6.png" alt="6"></p>
<center style="font-size:12px;font-weight:bold">Fig. 6. Sigmoid</center><br>

<p>Sigmoid is useful when we the output just has two possible value. So it often be used in the output layer of binary classification.</p>
<h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p><img src="/2023/04/10/NeuralNetwork/7.png" alt="7"></p>
<center style="font-size:12px;font-weight:bold">Fig. 7. ReLU</center><br>

<p>ReLU is one of the most commonly used activation function in <strong>hidden layer</strong>. As the slope of it does not change on the negative or positive semi-axis, the convergence speed of ReLU is much faster than Sigmoid. In addition, ReLU makes sense because it has a &quot;off&quot; point which enables neurons to stitch together to form complex non-linear functions:</p>
<p><img src="/2023/04/10/NeuralNetwork/8.png" alt="8"></p>
<center style="font-size:12px;font-weight:bold">Fig. 8. Unit0+Unit1+Unit2</center><br>

<blockquote>
<p>Andrew Ng suggests that for the output layer, we should select the activation function that produces the exact result we need, but for the hidden layer, it is advisable to choose ReLU as out default activation function.</p>
</blockquote>
<h1 id="Softmax-regression"><a href="#Softmax-regression" class="headerlink" title="Softmax regression"></a>Softmax regression</h1><p>Softmax regression or softmax activation function is used to deal with multiclass classification. Multiclass classification is an extension of binary classification. In multiclass classification, the number of output is more than two.</p>
<p><img src="/2023/04/10/NeuralNetwork/9.png" alt="9"></p>
<center style="font-size:12px;font-weight:bold">Fig. 9. Multiclass classification</center><br>

<p>In binary regression, $g(z)$ is actually the possibility of $a&#x3D;&#x3D;1$. We can also get the possibility of $a&#x3D;&#x3D;0$ which is $1-g(z)$. But in multiclass classification, we can not do that. To solve this, softmax calculates the probability of all possible values. We use $z_i$ to represent a possible value and $a_i$ to represent its possibility:<br>$$z_1&#x3D;\vec{w_1}\cdot\vec{x}+b_1;a_1&#x3D;\frac{e^{z_1}}{e^{z_1}+...+e^{z_n}}&#x3D;P(y&#x3D;1)|\vec{x})$$<br>$$...$$<br>$$z_n&#x3D;\vec{w_n}\cdot\vec{x}+b_n;a_n&#x3D;\frac{e^{z_n}}{e^<br>{z_1}+...+e^{z_n}}&#x3D;P(y&#x3D;n|\vec{x})$$<br>And the loss function is:<br>$$L(a_1,...,a_n,y)&#x3D;\begin{cases}<br>-\log{a_1},&amp;y&#x3D;1 \\<br>...&amp; \\<br>-log{a_n},&amp;y&#x3D;n<br>\end{cases}$$</p>
<p>The loss function will make $a_i$ tends to 1 when $y&#x3D;i$.Binary classfication is a special case where n&#x3D;2.</p>
<p>Softmax is a special activation in neural network as it is actually a layer. Its output is a vector whose elements are the possibility of values.</p>
<p><img src="/2023/04/10/NeuralNetwork/10.png" alt="10"></p>
<center style="font-size:12px;font-weight:bold">Fig. 10. Neural network with softmax</center>

<h1 id="Multi-label-classification"><a href="#Multi-label-classification" class="headerlink" title="Multi-label classification"></a>Multi-label classification</h1><p>Multi-label classification is another type of classification. In multi-label classification, we are required to classify a thing into as many labels as we want. To realize this, we just need to use several sigmoid functions in our output layer.</p>
<p><img src="/2023/04/10/NeuralNetwork/11.png" alt="11"></p>
<center style="font-size:12px;font-weight:bold">Fig. 11. Multi-label classification</center>

<h1 id="Adam-algorithm"><a href="#Adam-algorithm" class="headerlink" title="Adam algorithm"></a>Adam algorithm</h1><p>Adam algorithm is optimization of gradient descent, which will automatically modify $\alpha$. In adam algorithm, each neuron of the same layer has different $\alpha$ (the initial value is the same):</p>
<ul>
<li>If $w_j$ or $b$ keeps moving in the same direction, it increases $\alpha_j$;</li>
<li>If $w_j$ or $b$ keeps oscillating, it reduces $\alpha_j$.</li>
</ul>
<p><img src="/2023/04/10/NeuralNetwork/12.png" alt="12"></p>
<center style="font-size:12px;font-weight:bold">Fig. 12. Adam algorithm</center>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          </div>
          <script type="text/javascript">
          var tagsall=document.getElementsByClassName("post-tags")
          for (var i = tagsall.length - 1; i >= 0; i--){
            var tags=tagsall[i].getElementsByTagName("a");
            for (var j = tags.length - 1; j >= 0; j--) {
                var r=Math.floor(Math.random()*75+130);
                var g=Math.floor(Math.random()*75+100);
                var b=Math.floor(Math.random()*75+80);
                tags[j].style.background = "rgb("+r+","+g+","+b+")";
            }
          }                        
          </script>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/04/10/HexoConfiguration/" rel="prev" title="Hexo Configuration">
                  <i class="fa fa-angle-left"></i> Hexo Configuration
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/04/11/Conda/" rel="next" title="Conda">
                  Conda <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fas fa-star-of-david"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Chaolv Zeng</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Word count total: </span>
    <span title="Word count total">139k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">8:27</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

<!-- <br /> -->
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<!-- <span id="times">载入时分秒...</span> -->
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("11/17/2022 8:00:00");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); 
        if(String(snum).length ==1 ){snum = "0" + snum;}
        // var times = document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "+hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/fancybox.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":false,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
