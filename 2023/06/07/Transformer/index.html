<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=[object Object]"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '[object Object]');
</script>
<!-- End Google Analytics -->

  
  <title>Transformer: Self-Attention and Parallelization | JourneyToCoding</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="The transformer which is distinguished by its adoption of self-attention and multi-head attention, is a deep learning model using the encoder-decoder architecture. It can be used in both CV and NLP. T">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformer: Self-Attention and Parallelization">
<meta property="og:url" content="https://zclzcl0223.github.io/2023/06/07/Transformer/index.html">
<meta property="og:site_name" content="JourneyToCoding">
<meta property="og:description" content="The transformer which is distinguished by its adoption of self-attention and multi-head attention, is a deep learning model using the encoder-decoder architecture. It can be used in both CV and NLP. T">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/06/07/Transformer/1.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/06/07/Transformer/2.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/06/07/Transformer/2_1.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/06/07/Transformer/3.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/06/07/Transformer/4.png">
<meta property="article:published_time" content="2023-06-07T12:34:57.000Z">
<meta property="article:modified_time" content="2023-08-11T05:45:58.000Z">
<meta property="article:author" content="ChaosTsang">
<meta property="article:tag" content="Attention Mechanism">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zclzcl0223.github.io/2023/06/07/Transformer/1.png">
  
    <link rel="alternate" href="/atom.xml" title="JourneyToCoding" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/%5Bobject%20Object%5D">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">JourneyToCoding</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Code for fun</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/">home</a>
        
          <a class="main-nav-link" href="/about/">about</a>
        
          <a class="main-nav-link" href="/tags/">tags</a>
        
          <a class="main-nav-link" href="/categories/">categories</a>
        
          <a class="main-nav-link" href="/archives/">archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://zclzcl0223.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Transformer" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/06/07/Transformer/" class="article-date">
  <time class="dt-published" datetime="2023-06-07T12:34:57.000Z" itemprop="datePublished">2023-06-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Dive-Into-Deep-Learning/">Dive Into Deep Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Transformer: Self-Attention and Parallelization
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <span id="more"></span>

<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.03762.pdf">Transformer</a> deals with sequence based on the encoder-decoder architecture. Compared to seq2seq which uses attention mechanisms as well as RNNs, transformer is purely based on the attention mechanism. Both of its encoder and decoder consist of $n$ transformer blocks.</p>
<p><img src="/2023/06/07/Transformer/1.png" alt="1"></p>
<center style="font-size:12px; font-weight:bold">Fig. 1. Architecture of transformer</center><br>

<p>The outpur of encoder is $\mathbf{y}_1,...,\mathbf{y}_n$, where $\mathbf{y}_i$ is the encoding of the $i$-th token. Except for the last encoder block, the output of other encoder blocks is the input for their next encoder block. The output of the last encoder block is the keys and values for the multi-head attention layer of all the decoder blocks whose queries are the output of masked multi-head attention layer. As a result, the shape of the output of the encoder and decoder should be the same.</p>
<p><img src="/2023/06/07/Transformer/2.png" alt="2"></p>
<center style="font-size:12px; font-weight:bold">Fig. 2. Information transfer between encoder and decoder</center><br>

<blockquote>
<p>The code of transformer in PyTorch: <a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_attention-mechanisms/transformer.html">Dive into Deep Learning</a>.</p>
</blockquote>
<h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><ul>
<li>BatchNorm: The mean of each feature dimension becomes 0, and the variance becomes 1 (two-dimensional: column).</li>
<li>LayerNorm：The mean of all features of each sample becomes 0, and the variance becomes 1 (two-dimensional: row).</li>
</ul>
<p>But for sequence data, it is generally three-dimensional, that is <code>(batch_size, sequence_length, features)</code>. For different sequences, the effective length of the sequence may be different. At this time, the jitter of the mean and variance of different sequences calculated by BatchNorm will be larger, which will affect the global mean and variance, and when the length of the predicted sequence is much longer or shorter than the training sequence, the global mean and variance may not be very useful. LayerNorm normalizes all features of each sample, that is, each sample only considers itself, so it is relatively stable.</p>
<p><img src="/2023/06/07/Transformer/2_1.png" alt="2_1"></p>
<center style="font-size:12px; font-weight:bold">Fig. 3. BatchNorm and LayerNorm</center>

<h1 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h1><p>The encoder is made up of one embedding layer and $n$ encoder blocks. Each encoder block consists of two sublayers: multi-head self-attention and positionwise feed-forward networks. The shape of output of each layer is the same so hyperparameters that can be adjusted are the number of encoder block and the shape of output.</p>
<p>Inputs of encoder are keys, values and queries, which are all the source sequence. The shape of feature of the input after embedding layer is the same as the output. The input of the first encoder block is the original sequence after encoding while the others are outputs of the previous encoder block.</p>
<blockquote>
<p>All layers (except for the embedding layer) of encoder and decoder don&#39;t change the shape of samples.</p>
</blockquote>
<h2 id="Embedding-amp-Positional-Encoding"><a href="#Embedding-amp-Positional-Encoding" class="headerlink" title="Embedding &amp; Positional Encoding"></a>Embedding &amp; Positional Encoding</h2><p>The embedding layer maps the feature dimension of each key, value and query to the same dimension <code>num_hiddens</code>, which is the output dimension of the encoder, and then adds location information to all keys, values and queries.</p>
<blockquote>
<p>Since keys, values and queries are the same thing at this point, only one variable needs to be processed. <code>key_size</code>, <code>value_size</code>, and <code>query_size</code> which are the shape of features of keys, values and queries, are all the same thing.</p>
<p>Since the location information is between $-1$ and $1$, before adding the location information, it is necessary to multiply the samples processed by the embedding layer by the square root of <code>num_hiddens</code> in order to ensure that the value of the feature of each token is not much smaller than the location information.</p>
</blockquote>
<h2 id="Encoder-Block"><a href="#Encoder-Block" class="headerlink" title="Encoder Block"></a>Encoder Block</h2><p>The encoder block consists of two modules: a multi-head self-attention layer and a position-wise FFN layer. After each module, a residual connection and layer normalization are performed to train a deeper network (residual connection first and then layer normalization).</p>
<blockquote>
<p>This also reflects that in transformer, the feature dimensions of the input and output of each module are always constant. This is very different from the traditional CNNs.</p>
</blockquote>
<h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p>Transformer uses dot-product attention. Therefore, in order to allow the multi-head attention layer to have learned parameters, before each head of keys, values, and queries, they must first be newly mapped with a fully connected layer.</p>
<p><img src="/2023/06/07/Transformer/3.png" alt="3"></p>
<center style="font-size:12px; font-weight:bold">Fig. 4. Multi-head attention and fully connected layer</center><br>

<p>The attention is actually a weighted sum of different values, so the dot-product attention does not change the shape of input. However, the fully connected layer may change the shape of input. The feature dimension of the sample after the multi-head attention layer should remain unchanged, so the number of heads is actually related to the output dimension of the feature:</p>
<p>$$<br>\text{heads}\times\text{num_hiddens_FC}&#x3D;\text{num_hiddens}<br>$$</p>
<p>Therefore, the fully connected layers before different heads can be merged into a large fully connected layer with model parameters <code>W_q</code>, <code>W_k</code> and <code>W_v</code>, which process queries, keys, and values respectively. The output size of the layer is $\text{num_hiddens}$. In this way, the parallelism will be better.</p>
<p><img src="/2023/06/07/Transformer/4.png" alt="4"></p>
<center style="font-size:12px; font-weight:bold">Fig. 5. Large fully connected layer</center><br>

<blockquote>
<p>The shape of the output obtained from the above operations is <code>(batch_size, num_queries or key-value_pairs, num_hiddens)</code>. After the deformation operation, the shape can be changed to <code>(batch_size, num_queries or key-value_pairs, heads, num_hiddens/heads)</code>. In this way, the different heads are separated again, and the output of each head can be calculated independently. After the attention is gathered and the output of each head is concatenated, a linear transformation is performed again. This transformation still does not change the feature dimension, but increases the number of learned parameters (<code>W_o</code>).</p>
</blockquote>
<h3 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h3><p>This module is actually an MLP with only one hidden layer, which still does not change the feature dimension of the input.</p>
<h1 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h1><p>The decoder is made up of one embedding layer and $n$ decoder blocks. The input of decoder is targeted sequence. The input of the first decoder block is the targeted sequence after embedding layer while the others are outputs of the previous decoder block.</p>
<p>When making predictions, the work of the encoder has not changed, and the original sequence can be processed directly. The decoder, on the other hand, has to work sequentially because the predictions have to be obtained one by one. That is to say, when predicting the (t+1)-th output, the keys and values of input of decoder are 0~t predicted values, while the query is the t-th predicted value.</p>
<h2 id="Embedding-amp-Positional-Encoding-1"><a href="#Embedding-amp-Positional-Encoding-1" class="headerlink" title="Embedding &amp; Positional Encoding"></a>Embedding &amp; Positional Encoding</h2><p>Functions and operations are in the same way as the encoder, except that the input is the targeted sequence.</p>
<h2 id="Decoder-Block"><a href="#Decoder-Block" class="headerlink" title="Decoder Block"></a>Decoder Block</h2><p>The decoder block consists of three modules: masked multi-head attention, multi-head self-attention and position-wise FFN. Similar to the encoder, there are also residual connections and layer normalization after each module.</p>
<h3 id="Masked-Multi-Head-Attention"><a href="#Masked-Multi-Head-Attention" class="headerlink" title="Masked Multi-Head Attention"></a>Masked Multi-Head Attention</h3><p>This module extracts the feature information of the targeted sequence. Its mode is almost the same as the multi-head self-attention of the encoder. The difference is that it adds a mask operation. The purpose of the mask operation is to make the transformer have the same autoregressive behavior mode during training and prediction. At predicting time, the decoder cannot see all targeted sequences at once, while at training time it can. Therefore, during training, a mask is used to cover the tokens after the current time step, making it invisible.</p>
<p>The mechanism is to make the attention score of the token after the current time step be negative infinity before $\text{softmax}$, so that the attention weights assigned to them are infinitely close to $0$. Then, we can achieve the purpose of shielding future tokens:</p>
<p>$$<br>\text{softmax}(\text{masked}(\mathbf{QK}^\text{T}))\mathbf{V}<br>$$</p>
<h3 id="Multi-Head-Attention-1"><a href="#Multi-Head-Attention-1" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p>The same to the encoder, but the keys and values come from the final output of the encoder.</p>
<h3 id="Position-wise-Feed-Forward-Networks-1"><a href="#Position-wise-Feed-Forward-Networks-1" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h3><p>The same to the encoder.</p>
<h2 id="Dense-Layer"><a href="#Dense-Layer" class="headerlink" title="Dense Layer"></a>Dense Layer</h2><p>It is a fully connected layer that implements softmax regression.</p>
<blockquote>
<p>By default, PyTorch treats the last dimension as the feature dimension.</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zclzcl0223.github.io/2023/06/07/Transformer/" data-id="clzik1qu60090m07k4kbwf2e8" data-title="Transformer: Self-Attention and Parallelization" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Attention-Mechanism/" rel="tag">Attention Mechanism</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/06/07/PaperReading/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          找论文，读论文，用论文，写论文
        
      </div>
    </a>
  
  
    <a href="/2023/06/06/Attention/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Attention Mechanisms: More Targeted Information Extraction</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Advanced-Model/">Advanced Model</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS7313-Computational-Complexity/">CS7313: Computational Complexity</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Configuration/">Configuration</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Dive-Into-Deep-Learning/">Dive Into Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GNN/">GNN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kernel-Method/">Kernel Method</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MATH6005-Matrix-Theory/">MATH6005: Matrix Theory</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning-by-AndrewNg/">Machine Learning by AndrewNg</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/">Paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming-Language/">Programming Language</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tool/">Tool</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Attention-Mechanism/" rel="tag">Attention Mechanism</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Configuration/" rel="tag">Configuration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Analysis/" rel="tag">Data Analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dataset-Distillation/" rel="tag">Dataset Distillation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Trees/" rel="tag">Decision Trees</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GCN/" rel="tag">GCN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GNN/" rel="tag">GNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Generative-AI/" rel="tag">Generative AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/" rel="tag">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lab/" rel="tag">Lab</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markup-Language/" rel="tag">Markup Language</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Paper/" rel="tag">Paper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Recommender-System/" rel="tag">Recommender System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reinforcement-Learning/" rel="tag">Reinforcement Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Supervised-Learning/" rel="tag">Supervised Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Theoretical-Computer-Science/" rel="tag">Theoretical Computer Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/" rel="tag">Tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Unsupervised-Learning/" rel="tag">Unsupervised Learning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Attention-Mechanism/" style="font-size: 11.82px;">Attention Mechanism</a> <a href="/tags/CNN/" style="font-size: 12.73px;">CNN</a> <a href="/tags/Configuration/" style="font-size: 10px;">Configuration</a> <a href="/tags/Data-Analysis/" style="font-size: 10px;">Data Analysis</a> <a href="/tags/Dataset-Distillation/" style="font-size: 13.64px;">Dataset Distillation</a> <a href="/tags/Decision-Trees/" style="font-size: 10px;">Decision Trees</a> <a href="/tags/Deep-Learning/" style="font-size: 20px;">Deep Learning</a> <a href="/tags/GCN/" style="font-size: 11.82px;">GCN</a> <a href="/tags/GNN/" style="font-size: 15.45px;">GNN</a> <a href="/tags/Generative-AI/" style="font-size: 10.91px;">Generative AI</a> <a href="/tags/Hexo/" style="font-size: 10.91px;">Hexo</a> <a href="/tags/Lab/" style="font-size: 10.91px;">Lab</a> <a href="/tags/Linux/" style="font-size: 16.36px;">Linux</a> <a href="/tags/Machine-Learning/" style="font-size: 17.27px;">Machine Learning</a> <a href="/tags/Markup-Language/" style="font-size: 10px;">Markup Language</a> <a href="/tags/Math/" style="font-size: 19.09px;">Math</a> <a href="/tags/Paper/" style="font-size: 14.55px;">Paper</a> <a href="/tags/Python/" style="font-size: 18.18px;">Python</a> <a href="/tags/RNN/" style="font-size: 10.91px;">RNN</a> <a href="/tags/Recommender-System/" style="font-size: 10.91px;">Recommender System</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 10.91px;">Reinforcement Learning</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/Supervised-Learning/" style="font-size: 11.82px;">Supervised Learning</a> <a href="/tags/Theoretical-Computer-Science/" style="font-size: 15.45px;">Theoretical Computer Science</a> <a href="/tags/Tool/" style="font-size: 18.18px;">Tool</a> <a href="/tags/Unsupervised-Learning/" style="font-size: 11.82px;">Unsupervised Learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/06/17/Diffusion/">Diffusion</a>
          </li>
        
          <li>
            <a href="/2024/01/20/VAE/">VAE</a>
          </li>
        
          <li>
            <a href="/2023/12/02/CountingComplexity/">Computational Complexity: Complexity of Counting</a>
          </li>
        
          <li>
            <a href="/2023/11/24/MatrixTheory5/">MatrixTheory: 特殊矩阵与矩阵分解</a>
          </li>
        
          <li>
            <a href="/2023/11/13/RandomizedComputation/">Computational Complexity: Randomized Computation</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 ChaosTsang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/" class="mobile-nav-link">home</a>
  
    <a href="/about/" class="mobile-nav-link">about</a>
  
    <a href="/tags/" class="mobile-nav-link">tags</a>
  
    <a href="/categories/" class="mobile-nav-link">categories</a>
  
    <a href="/archives/" class="mobile-nav-link">archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>





<script src="/js/script.js"></script>





  </div>
</body>
</html>