<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=[object Object]"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '[object Object]');
</script>
<!-- End Google Analytics -->

  
  <title>MatrixTheory: 特殊矩阵与矩阵分解 | JourneyToCoding</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="矩阵理论第六课，主要讲特殊矩阵与矩阵分解。">
<meta property="og:type" content="article">
<meta property="og:title" content="MatrixTheory: 特殊矩阵与矩阵分解">
<meta property="og:url" content="https://zclzcl0223.github.io/2023/11/24/MatrixTheory5/index.html">
<meta property="og:site_name" content="JourneyToCoding">
<meta property="og:description" content="矩阵理论第六课，主要讲特殊矩阵与矩阵分解。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-24T04:26:01.000Z">
<meta property="article:modified_time" content="2023-12-30T12:38:50.000Z">
<meta property="article:author" content="ChaosTsang">
<meta property="article:tag" content="Math">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="JourneyToCoding" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/%5Bobject%20Object%5D">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">JourneyToCoding</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Code for fun</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/">home</a>
        
          <a class="main-nav-link" href="/about/">about</a>
        
          <a class="main-nav-link" href="/tags/">tags</a>
        
          <a class="main-nav-link" href="/categories/">categories</a>
        
          <a class="main-nav-link" href="/archives/">archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://zclzcl0223.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-MatrixTheory5" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/11/24/MatrixTheory5/" class="article-date">
  <time class="dt-published" datetime="2023-11-24T04:26:01.000Z" itemprop="datePublished">2023-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/MATH6005-Matrix-Theory/">MATH6005: Matrix Theory</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      MatrixTheory: 特殊矩阵与矩阵分解
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <span id="more"></span>

<h1 id="特殊矩阵"><a href="#特殊矩阵" class="headerlink" title="特殊矩阵"></a>特殊矩阵</h1><p>一些复数域的特殊矩阵。</p>
<h2 id="正规矩阵"><a href="#正规矩阵" class="headerlink" title="正规矩阵"></a>正规矩阵</h2><p>复数域可酉对角化（不一定正交对角化）的矩阵。$Q^* &#x3D; Q ^{-1}$。</p>
<p>$$<br>Q^* A Q &#x3D; \Lambda<br>$$</p>
<p>定义：复数域上的方阵，满足$AA^*&#x3D;A^*A$</p>
<h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><ol>
<li>与正规矩阵酉相似的矩阵还是正规矩阵，即$B &#x3D; Q^*A Q$，其中$A$是正规矩阵，则$B$也是正规矩阵。</li>
<li>$A$为正规三角矩阵，则$A$一定为对角矩阵。</li>
<li>$A$为正规矩阵$\iff$$A$可酉对角化。</li>
</ol>
<blockquote>
<p>左到右：舒尔定理——复数域的方阵一定可酉相似于三角矩阵。而正规三角矩阵一定为对角矩阵。</p>
</blockquote>
<p>实数域的正规矩阵：$A ^T &#x3D; A$，$A ^T &#x3D; -A$，$A ^T &#x3D; A ^{-1}$<br>复数域的正规矩阵：$A^* &#x3D; A$，$A^* &#x3D; -A$，$A^* &#x3D; A ^{-1}$</p>
<h4 id="Hermite矩阵：-A-x3D-A"><a href="#Hermite矩阵：-A-x3D-A" class="headerlink" title="Hermite矩阵：$A^* &#x3D; A$"></a>Hermite矩阵：$A^* &#x3D; A$</h4><p>实对称矩阵的推广。性质：</p>
<ol>
<li>特征值都是实数，类似地，反Hermite矩阵的特征值都是纯虚数或0。</li>
<li>复二次型：$x^* A x$（一定是实数），相应地，可定义正定、标准化。</li>
</ol>
<blockquote>
<p>等积变换：正交变换、酉变换$x &#x3D; Qy$</p>
</blockquote>
<h4 id="酉矩阵：-AA-x3D-A-A-x3D-E"><a href="#酉矩阵：-AA-x3D-A-A-x3D-E" class="headerlink" title="酉矩阵：$AA^*&#x3D;A^*A&#x3D;E$"></a>酉矩阵：$AA^*&#x3D;A^*A&#x3D;E$</h4><ol>
<li>特征值模为1。</li>
</ol>
<h1 id="矩阵分解（20-30分）"><a href="#矩阵分解（20-30分）" class="headerlink" title="矩阵分解（20~30分）"></a>矩阵分解（20~30分）</h1><h2 id="满秩分解"><a href="#满秩分解" class="headerlink" title="满秩分解"></a>满秩分解</h2><p>化埃尔米特标准型求。四个子空间。</p>
<blockquote>
<p>可能能用于求矩阵的次方。如$A ^2 &#x3D; PQPQ&#x3D;P(QP)Q$。特别是对于$A$的秩为1的时候，$P$和$Q$都是向量，此时$QP$是一个数。</p>
</blockquote>
<h2 id="正交三角分解"><a href="#正交三角分解" class="headerlink" title="正交三角分解"></a>正交三角分解</h2><p>$A _{m\times n}$：必须列满秩才有正交三角分解。</p>
<p>$$<br>A _{m\times n}&#x3D; U _{m \times n}R _{n \times n}<br>$$</p>
<p>其中$U$的列向量单位正交，$R$是主对角元大于0的上三角。</p>
<blockquote>
<p>$U$即为$A$的列向量的斯密特单位正交化。$R _{ij}&#x3D;(\alpha _i, \gamma _j)(i \ne j),R _{ii}&#x3D;||\beta _i||$且上三角。或者$R &#x3D; U^* A$。</p>
<p>正交三角分解是唯一的。</p>
<p>应用：解线性方程组。</p>
</blockquote>
<h2 id="谱分解"><a href="#谱分解" class="headerlink" title="谱分解"></a>谱分解</h2><p>$A _{n \times n}$：可对角化的方阵才有谱分解。</p>
<p>$P&#x3D;(\alpha _1, \alpha _2,..., \alpha _n)$，其中$\alpha _i$为特征向量。</p>
<p>最基本的谱分解：<br>$$<br>A &#x3D; (\alpha _1,...,\alpha _n)eye(\lambda _1,...,\lambda _n)(\beta _1 ^T,...,\beta _n ^T)<br>$$</p>
<p>其中$P ^{-1}&#x3D;(\beta _1 ^T,...,\beta _n ^T)$（竖着的）</p>
<p>于是：</p>
<p>$$<br>A &#x3D; \lambda _1 \alpha _1 \beta _1 ^T +...+ \lambda _n \alpha _n \beta _n ^T<br>$$</p>
<p>记$S _1,..., S _m$为不同的特征值，则：</p>
<p>$$<br>A &#x3D; S _1 G _1+...+ S _m G _m<br>$$</p>
<p>性质：</p>
<ol>
<li>$\sum _{i &#x3D; 1} ^m G _i &#x3D; E$</li>
<li>$\beta _i ^T \alpha _j &#x3D; 1 (i &#x3D; j);0 (i \ne j)$。$(\alpha _i \beta _i ^T) ^2 &#x3D; \alpha _i \beta _i ^T$，$(\alpha _i \beta _i ^T)(\alpha _j \beta _j ^T) &#x3D; 0 (i \ne j)$。故$G _i ^2 &#x3D; G _i$，$G _i G _j &#x3D; 0 (i \ne j)$。</li>
<li>$r (G _i) &#x3D; n _i (\text{特征值的代数重数})$。</li>
<li>谱分解唯一。用性质1、2证明。</li>
</ol>
<p>正规矩阵的谱分解：不需要专门求逆矩阵。</p>
<p>$$<br>A ^2 &#x3D; \sum \lambda _i ^2 G _i<br>$$</p>
<h2 id="三角分解（cholesky分解）"><a href="#三角分解（cholesky分解）" class="headerlink" title="三角分解（cholesky分解）"></a>三角分解（cholesky分解）</h2><p>$A _{n\times n}$：秩为$r$的方阵，$A&#x3D;LU$，其中$L$为单位下三角，$U$是上三角。</p>
<ul>
<li>条件：1~r阶顺序主子式非零。</li>
</ul>
<p>本质是高斯消元：即行变换相当于左乘矩阵，让行变换后的矩阵是个上三角，此时左乘的矩阵一定是一个单位下三角。由于左乘的单位下三角是可逆的，故左乘其逆矩阵即可得到$A&#x3D;LU$。</p>
<ul>
<li>注：此时的行变换只能用上面的行去减下面的行。</li>
</ul>
<h3 id="实正定矩阵"><a href="#实正定矩阵" class="headerlink" title="实正定矩阵"></a>实正定矩阵</h3><p>首先，一定有三角分解，但是更特殊，称Cholesky分解：$A&#x3D;R ^T R$。$R$为主对角元大于零的上三角。</p>
<p>因为正定矩阵一定是对称的，所以可以正交相似对角化：$Q ^TA Q&#x3D;\Lambda$，可得$A &#x3D; Q\Lambda Q ^T&#x3D;Q\sqrt{\Lambda}\sqrt{\Lambda}Q ^T&#x3D;(\sqrt{\Lambda}Q ^T) ^T (\sqrt{\Lambda}Q ^T)&#x3D;B ^T B&#x3D;(\sqrt{\Lambda}Q ^T) ^T Q ^T Q(\sqrt{\Lambda}Q ^T)&#x3D;(Q\sqrt{\Lambda}Q ^T) ^T(Q\sqrt{\Lambda}Q ^T) &#x3D;C ^TC$，显然，$C$是一个正定矩阵。</p>
<p>而$B$是满秩的，所以一定有正交三角分解，即$B &#x3D; UR$，$U$为正交矩阵，于是$B ^TB&#x3D;(UR) ^T(UR)&#x3D;R ^TR$，即为所求。</p>
<blockquote>
<p>这样的分解是唯一的。</p>
</blockquote>
<p>求法：同时行列变换（仍然只能上减下、左减右），将$A$化为对角矩阵，分别左右乘逆矩阵，然后对角矩阵开根号，前两个当一个矩阵，后两个当一个矩阵即可。</p>
<h2 id="奇异值分解（极分解）"><a href="#奇异值分解（极分解）" class="headerlink" title="奇异值分解（极分解）"></a>奇异值分解（极分解）</h2><p>$A _{m\times n}$，$r(A) &#x3D; r$，$A _{m\times n}&#x3D; U _{m\times m} D _{m\times n} V^* _{n\times n}$，其中$U,V$是酉矩阵，$D$的所有元素中只有主对角线上前面的元素$\delta _i$非零，$\delta _i &gt; 0,0\le i\le r$，$\delta _i$称为$A$的奇异值。</p>
<ul>
<li>奇异值：$A A^*$的特征值开根号。</li>
<li>$U$：$A A^*$特征值的单位正交向量组成的矩阵。</li>
<li>$V$：$A^* A$特征值的单位正交向量组成的矩阵。</li>
</ul>
<h3 id="一些性质"><a href="#一些性质" class="headerlink" title="一些性质"></a>一些性质</h3><ul>
<li>$r(A) &#x3D; r (A^*) &#x3D; r (AA^*) &#x3D; r (A^* A)$：即证$N(A)&#x3D;N(AA^*)$。</li>
<li>$AA^*$与$A^* A$的非零特征值完全一样：$A^* A$特征值为$\lambda$，特征向量为$\alpha$，则$AA^*$的特征值为$\lambda$，特征向量为$A \alpha$。</li>
<li>$A^* A$和$A A^*$都是半正定矩阵，特征值开根号即为奇异值。</li>
<li>设$\lambda$为$A^* A$的一个非零特征值，$\alpha _1,...,\alpha _k$为其单位正交特征向量，则$\lambda$为$A A^*$特征向量，$A\alpha _1,...,A\alpha _k$为其正交特征向量，但不是单位的，要除以$\sqrt{\lambda}$（即奇异值）才是单位化的。</li>
</ul>
<h3 id="奇异值分解求法"><a href="#奇异值分解求法" class="headerlink" title="奇异值分解求法"></a>奇异值分解求法</h3><ol>
<li>求$A^*A$<strong>大于0</strong>的特征值$\lambda _i$，及其对应的<strong>单位正交</strong>的特征向量$\alpha _i$；求0特征值对应的<strong>单位正交</strong>的特征向量$\alpha _{i+1}$。</li>
<li>求$AA^*$<strong>大于0</strong>的特征值（和$A^*A$）相同，及其对应的<strong>单位正交</strong>的特征向量$\beta _i$（$\beta _i &#x3D; (A \alpha _i) &#x2F; \sqrt{\lambda _i}$）；求0特征值对应的<strong>单位正交</strong>的特征向量$(\beta _{i+1})$。（无特殊求法）</li>
</ol>
<p>$A(\alpha _1,..., \alpha _i, \alpha _{i+1}, ...,\alpha _n)&#x3D;(\beta _1,...,\beta _i,\beta _{i+1},..,\beta _n)\Lambda(\sqrt{\lambda _1},..,\sqrt{\lambda _i},0,...,0)$，故$A&#x3D;UDV^*$。其中$U&#x3D;(\beta _1,...,\beta _i,\beta _{i+1},..,\beta _n)$，$V&#x3D;(\alpha _1,..., \alpha _i, \alpha _{i+1}, ...,\alpha _n)$。</p>
<blockquote>
<p>先求$AA^*$还是$A^*A$看哪个阶数小。</p>
</blockquote>
<p>$\alpha _1,..,\alpha _i$是$A$的行空间中的向量，$\beta _1,..,\beta _i$是$A$的列空间中的向量；$\alpha _{i+1},...,\alpha _n$是$N(A)$的向量，$\beta _{i+1},..,\beta _n$是$N ^T(A)$中的向量。</p>
<h3 id="极分解"><a href="#极分解" class="headerlink" title="极分解"></a>极分解</h3><p>若$A$是方阵，则$A&#x3D;UDV^*&#x3D;(UDU^*)(UV^*)$，其中，左边是一个半正定矩阵，右边是酉矩阵，这就是极分解。或者$A&#x3D;(UV^*)(VDV^*)$，其中左边是酉矩阵，右边是半正定矩阵。若$A$可逆，则为半正定变为正定。</p>
<h3 id="A是正规矩阵"><a href="#A是正规矩阵" class="headerlink" title="A是正规矩阵"></a>A是正规矩阵</h3><p>原始式很重要。牢记，有些就是对原始式做变形。</p>
<h1 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h1><h2 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h2><p>长度的推广。</p>
<p>满足性质：</p>
<ol>
<li>$||\alpha|| &gt; 0$，正定性</li>
<li>$||k \cdot \alpha|| &#x3D; |k| ||\alpha||$，齐次性</li>
<li>$||\alpha + \beta|| \le ||\alpha|| + ||\beta||$，三角不等式</li>
</ol>
<p>非负函数。</p>
<blockquote>
<p>定义了范数的线性空间称<em>赋范线性空间</em>。</p>
</blockquote>
<ul>
<li>$\mathcal{l} _1$：$\sum |x _i|$</li>
<li>$\mathcal{l} _2$：$(\sum |x _i| ^2) ^{1&#x2F;2}$</li>
<li>$\mathcal{l} _p$：$(\sum |x _i| ^p) ^{1&#x2F;p}(p \ge 1)$</li>
<li>$\mathcal{l} _\infty$：$\max\{|x _i|,1\le i\le n\}$</li>
</ul>
<p>以上统称$p$范数。向量范数是等价的。等价：</p>
<p>$$<br>c _1,c _2, c _2||\alpha|| _b \le ||\alpha|| _a\le c _1||\alpha|| _b<br>$$</p>
<h2 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h2><p>除前面三条性质外，还有：</p>
<ul>
<li>$|||AB||| \le |||A|||\space |||B|||$</li>
</ul>
<p>F范数：</p>
<ul>
<li>$|||A||| _F&#x3D;(\sum |a _{ij}| ^2) ^{1&#x2F;2}&#x3D;\sqrt{\text{tr}(AA^*)}&#x3D;\sqrt{\text{tr}(A^*A)}$</li>
</ul>
<p>Schur不等式，$A &#x3D; (a _{ij}) _{n\times n},\lambda _1,...,\lambda _n$，则：</p>
<p>$$<br>\sum |\lambda _i| ^2 \le \sum |a _{ij}| ^2\iff\text{A是正规矩阵取等号}<br>$$</p>
<p>Schur定理：$Q^* A Q &#x3D; \text{diag}(\lambda _1, ...,\lambda _n)+\text{上三角}$，其中$Q^*&#x3D;Q ^{-1}$。</p>
<h2 id="相容"><a href="#相容" class="headerlink" title="相容"></a>相容</h2><p>若</p>
<p>$$<br>||A \alpha|| \le |||A|||\cdot ||\alpha||<br>$$<br>其中$A$是矩阵，$\alpha$是向量，则称这两个范数是相容的。</p>
<h3 id="算子范数"><a href="#算子范数" class="headerlink" title="算子范数"></a>算子范数</h3><p>由向量范数$||\cdot|| _a$构造相容的矩阵范数：</p>
<p>$$<br>|||A|||&#x3D;\max _{x \ne 0,x \in C ^n}\frac{||Ax|| _a}{||x|| _a}&#x3D;\max _{||x|| _a&#x3D;1}||Ax|| _a<br>$$</p>
<p>如$||\alpha|| _2$导出的矩阵范数：</p>
<p>$$<br>|||A||| _2&#x3D;&#x3D;\max _{||x|| _2&#x3D;1}||Ax|| _2<br>$$</p>
<p>$$<br>||Ax|| _2 ^2&#x3D;(Ax,Ax)&#x3D;x^* A^* Ax<br>$$</p>
<p>设$A^*A$的$n$个特征值为$\lambda _1\ge ...\ge \lambda _n \ge 0$，对应的单位正交特征向量为$\alpha _1,...,\alpha _n$。显然，这是$C ^n$的一组基，故：</p>
<p>$$<br>x &#x3D; x _1\alpha _1+...+x _n \alpha _n<br>$$</p>
<p>$$<br>x^*&#x3D; \overline{x} _1\alpha _1^*+...+\overline{x} _n \alpha _n^*<br>$$</p>
<p>$$<br>x^* A^* A x&#x3D;(\overline{x} _1\alpha _1^*+...+\overline{x} _n \alpha _n^*)A^* A(x _1\alpha _1+...+x _n \alpha _n)<br>$$</p>
<p>即：</p>
<p>$$<br>\begin{align*}<br>x^* A^* A x<br>&amp;&#x3D;(\overline{x} _1\alpha _1^*+...+\overline{x} _n \alpha _n^*)(x _1\lambda _1\alpha _1+...+x _n\lambda _n \alpha _n)\\<br>&amp;&#x3D;\lambda _1 |x _1| ^2+...+\lambda _n |x _n| ^2\\<br>&amp;\le \lambda _1(|x _1| ^2+...+ |x _n| ^2)<br>\end{align*}<br>$$</p>
<p>而可以取等，所以$x^* A^* Ax &#x3D; \lambda _1$，$|||A||| _2 &#x3D;\sqrt{\lambda _1}$。其中$\lambda _1$为最大特征值。<em>称谱范数</em>。</p>
<blockquote>
<p>作业：求$||\alpha|| _1$和$||\alpha|| _\infty$的导出的矩阵算子范数。（提示：矩阵行取模最大、列取模最大）。</p>
</blockquote>
<h2 id="向量、矩阵序列的收敛性"><a href="#向量、矩阵序列的收敛性" class="headerlink" title="向量、矩阵序列的收敛性"></a>向量、矩阵序列的收敛性</h2><p>向量序列$x ^{(k)}&#x3D;(x _1 ^{(k)},...,x _n ^{(k)}) ^T$，收敛：$\lim _{k \to \infty} x ^{(k)}&#x3D;x\iff \lim _{k\to \infty}||x ^{(k)}-x||&#x3D;0$。</p>
<p>同理，可定义矩阵序列及其收敛。</p>
<blockquote>
<p>矩阵或向量的收敛是每个元素都收敛到一个值。</p>
</blockquote>
<p>矩阵的幂序列：$A ^{(k)}&#x3D; A ^k$。化为Jordan标准型，Jordan块的$k$次方，二项展开i即可，不用记公式。</p>
<ul>
<li>$|\lambda| _i &lt; 1$，收敛到0；</li>
<li>$|\lambda| _i&#x3D;1$且$\lambda _i &#x3D; 1$且$m &#x3D; 1$，收敛；</li>
<li>其他发散</li>
</ul>
<p>故，矩阵的谱半径小于$1$时幂矩阵序列幂收敛到0。</p>
<h2 id="谱半径范数是最小的矩阵范数"><a href="#谱半径范数是最小的矩阵范数" class="headerlink" title="谱半径范数是最小的矩阵范数"></a>谱半径范数是最小的矩阵范数</h2><p>$\rho (A) \le |||A|||$</p>
<blockquote>
<p>证明：令$B &#x3D; A &#x2F; (|||A|||+\epsilon)$，则$|||B|||&#x3D;|||A|||&#x2F;(|||A|||+\epsilon) &lt; 1$。</p>
</blockquote>
<h2 id="矩阵级数"><a href="#矩阵级数" class="headerlink" title="矩阵级数"></a>矩阵级数</h2><p>向量&#x2F;矩阵序列的项相加。$\sum _{k&#x3D;0} ^{\infty}A ^{(k)}$。收敛即$\sum a _{ij} ^{(k)}$都收敛。</p>
<h3 id="矩阵幂级数"><a href="#矩阵幂级数" class="headerlink" title="矩阵幂级数"></a>矩阵幂级数</h3><p>$\sum _{k&#x3D;0} ^\infty a _k A ^k$收敛性与$f(t)&#x3D;\sum _{k&#x3D;0} ^\infty a _k t ^k$有关。假设为Jordan块，则每一行的和就是$f(\lambda)$的泰勒级数。最终：</p>
<p>$$<br>\sum a _k A ^k &#x3D; P\text{diag}(f(J _1),...,f(J _s))p ^{-1}<br>$$</p>
<p>其中$\rho(A)&lt; r$，其中$r$为数项幂级数的收敛半径。</p>
<h3 id="矩阵函数"><a href="#矩阵函数" class="headerlink" title="矩阵函数"></a>矩阵函数</h3><p>$e ^A$，$\sin A$,$\cos A$：可泰勒展开化为矩阵多项式求。而矩阵多项式又可用哈密尔顿凯勒定理求：</p>
<ul>
<li>哈密尔顿凯勒定理求：$A ^n$可由$A ^{n-1},...,E$线性表示。即$f(A)&#x3D;\varPhi(\lambda)g+\text{余式}$。其中$g$是某个零化多项式，$\text{余式}$是比它低一次的多项式。只要待定系数求出余式的系数即可，带入的数是零化多项式的根（缺少约束就两边求导）。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zclzcl0223.github.io/2023/11/24/MatrixTheory5/" data-id="clzik0lcm005cv47k9gtdeiiw" data-title="MatrixTheory: 特殊矩阵与矩阵分解" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Math/" rel="tag">Math</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/12/02/CountingComplexity/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Computational Complexity: Complexity of Counting
        
      </div>
    </a>
  
  
    <a href="/2023/11/13/RandomizedComputation/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Computational Complexity: Randomized Computation</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Advanced-Model/">Advanced Model</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS7313-Computational-Complexity/">CS7313: Computational Complexity</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Configuration/">Configuration</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Dive-Into-Deep-Learning/">Dive Into Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GNN/">GNN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kernel-Method/">Kernel Method</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MATH6005-Matrix-Theory/">MATH6005: Matrix Theory</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning-by-AndrewNg/">Machine Learning by AndrewNg</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/">Paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming-Language/">Programming Language</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tool/">Tool</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Attention-Mechanism/" rel="tag">Attention Mechanism</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Configuration/" rel="tag">Configuration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Analysis/" rel="tag">Data Analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dataset-Distillation/" rel="tag">Dataset Distillation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Trees/" rel="tag">Decision Trees</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GCN/" rel="tag">GCN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GNN/" rel="tag">GNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Generative-AI/" rel="tag">Generative AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/" rel="tag">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lab/" rel="tag">Lab</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markup-Language/" rel="tag">Markup Language</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Paper/" rel="tag">Paper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Recommender-System/" rel="tag">Recommender System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reinforcement-Learning/" rel="tag">Reinforcement Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Supervised-Learning/" rel="tag">Supervised Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Theoretical-Computer-Science/" rel="tag">Theoretical Computer Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/" rel="tag">Tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Unsupervised-Learning/" rel="tag">Unsupervised Learning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Attention-Mechanism/" style="font-size: 11.82px;">Attention Mechanism</a> <a href="/tags/CNN/" style="font-size: 12.73px;">CNN</a> <a href="/tags/Configuration/" style="font-size: 10px;">Configuration</a> <a href="/tags/Data-Analysis/" style="font-size: 10px;">Data Analysis</a> <a href="/tags/Dataset-Distillation/" style="font-size: 13.64px;">Dataset Distillation</a> <a href="/tags/Decision-Trees/" style="font-size: 10px;">Decision Trees</a> <a href="/tags/Deep-Learning/" style="font-size: 20px;">Deep Learning</a> <a href="/tags/GCN/" style="font-size: 11.82px;">GCN</a> <a href="/tags/GNN/" style="font-size: 15.45px;">GNN</a> <a href="/tags/Generative-AI/" style="font-size: 10.91px;">Generative AI</a> <a href="/tags/Hexo/" style="font-size: 10.91px;">Hexo</a> <a href="/tags/Lab/" style="font-size: 10.91px;">Lab</a> <a href="/tags/Linux/" style="font-size: 16.36px;">Linux</a> <a href="/tags/Machine-Learning/" style="font-size: 17.27px;">Machine Learning</a> <a href="/tags/Markup-Language/" style="font-size: 10px;">Markup Language</a> <a href="/tags/Math/" style="font-size: 19.09px;">Math</a> <a href="/tags/Paper/" style="font-size: 14.55px;">Paper</a> <a href="/tags/Python/" style="font-size: 18.18px;">Python</a> <a href="/tags/RNN/" style="font-size: 10.91px;">RNN</a> <a href="/tags/Recommender-System/" style="font-size: 10.91px;">Recommender System</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 10.91px;">Reinforcement Learning</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/Supervised-Learning/" style="font-size: 11.82px;">Supervised Learning</a> <a href="/tags/Theoretical-Computer-Science/" style="font-size: 15.45px;">Theoretical Computer Science</a> <a href="/tags/Tool/" style="font-size: 18.18px;">Tool</a> <a href="/tags/Unsupervised-Learning/" style="font-size: 11.82px;">Unsupervised Learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/06/17/Diffusion/">Diffusion</a>
          </li>
        
          <li>
            <a href="/2024/01/20/VAE/">VAE</a>
          </li>
        
          <li>
            <a href="/2023/12/02/CountingComplexity/">Computational Complexity: Complexity of Counting</a>
          </li>
        
          <li>
            <a href="/2023/11/24/MatrixTheory5/">MatrixTheory: 特殊矩阵与矩阵分解</a>
          </li>
        
          <li>
            <a href="/2023/11/13/RandomizedComputation/">Computational Complexity: Randomized Computation</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 ChaosTsang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/" class="mobile-nav-link">home</a>
  
    <a href="/about/" class="mobile-nav-link">about</a>
  
    <a href="/tags/" class="mobile-nav-link">tags</a>
  
    <a href="/categories/" class="mobile-nav-link">categories</a>
  
    <a href="/archives/" class="mobile-nav-link">archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>





<script src="/js/script.js"></script>





  </div>
</body>
</html>