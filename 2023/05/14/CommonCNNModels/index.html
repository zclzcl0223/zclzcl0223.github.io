<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zclzcl0223.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12,"onmobile":false},"hljswrap":true,"copycode":{"enable":true,"style":"mac","show_result":false},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Some commonly used CNN models: LeNet-5, AlexNet, VGG, NiN, GoogLeNet, ResNet.">
<meta property="og:type" content="article">
<meta property="og:title" content="Common CNN Models">
<meta property="og:url" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/index.html">
<meta property="og:site_name" content="JourneyToCoding">
<meta property="og:description" content="Some commonly used CNN models: LeNet-5, AlexNet, VGG, NiN, GoogLeNet, ResNet.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/1.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/2.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/3.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/4.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/5.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/6.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/7.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/8.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/9.png">
<meta property="article:published_time" content="2023-05-14T04:33:39.000Z">
<meta property="article:modified_time" content="2023-08-09T05:48:32.000Z">
<meta property="article:author" content="Chaolv Zeng">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="CNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/1.png">


<link rel="canonical" href="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/","path":"2023/05/14/CommonCNNModels/","title":"Common CNN Models"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Common CNN Models | JourneyToCoding</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <a target="_blank" rel="noopener" href="https://github.com/zclzcl0223" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">JourneyToCoding</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Code for Fun</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#LeNet-5"><span class="nav-number">1.</span> <span class="nav-text">LeNet-5</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#AlexNet"><span class="nav-number">2.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VGG"><span class="nav-number">3.</span> <span class="nav-text">VGG</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NiN"><span class="nav-number">4.</span> <span class="nav-text">NiN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#GoogLeNet"><span class="nav-number">5.</span> <span class="nav-text">GoogLeNet</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Batch-normalization"><span class="nav-number">5.1.</span> <span class="nav-text">Batch normalization</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ResNet"><span class="nav-number">6.</span> <span class="nav-text">ResNet</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Chaolv Zeng"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Chaolv Zeng</p>
  <div class="site-description" itemprop="description">Start of Something New</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">104</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zclzcl0223" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zclzcl0223" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chaostsang0223@gmail.com" title="E-Mail → mailto:chaostsang0223@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="sidebar-inner sidebar-post-related">
          <div class="animated">
              <div class="links-of-blogroll-title"><i class="fa fa-signs-post fa-fw"></i>
    Related Posts
  </div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/05/10/CNN/" rel="bookmark">
        <time class="popular-posts-time">2023-05-10</time>
        <br>
      CNN: Feature Extraction
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/05/07/NumericalStability/" rel="bookmark">
        <time class="popular-posts-time">2023-05-07</time>
        <br>
      Numerical Stability
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/06/07/Transformer/" rel="bookmark">
        <time class="popular-posts-time">2023-06-07</time>
        <br>
      Transformer: Self-Attention and Parallelization
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/05/29/CommonRNNModels/" rel="bookmark">
        <time class="popular-posts-time">2023-05-29</time>
        <br>
      Common RNN Models
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/04/10/NeuralNetwork/" rel="bookmark">
        <time class="popular-posts-time">2023-04-10</time>
        <br>
      Neural Network
      </a>
    </li>
  </ul>

          </div>
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chaolv Zeng">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JourneyToCoding">
      <meta itemprop="description" content="Start of Something New">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Common CNN Models | JourneyToCoding">
      <meta itemprop="description" content="Some commonly used CNN models: LeNet-5, AlexNet, VGG, NiN, GoogLeNet, ResNet.">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Common CNN Models
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-14 12:33:39" itemprop="dateCreated datePublished" datetime="2023-05-14T12:33:39+08:00">2023-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-08-09 13:48:32" itemprop="dateModified" datetime="2023-08-09T13:48:32+08:00">2023-08-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Dive-Into-Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Dive Into Deep Learning</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>2.5k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>9 mins.</span>
    </span>
</div>

            <div class="post-description">Some commonly used CNN models: LeNet-5, AlexNet, VGG, NiN, GoogLeNet, ResNet.</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><span id="more"></span>

<h1 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h1><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/726791">LeNet-5</a> which was published in 1998, is one of the simplest CNN models. It was originally used to recognize handwritten numbers between 0 and 9.</p>
<p><img src="/2023/05/14/CommonCNNModels/1.png" alt="1"></p>
<center style="font-size:12px;font-weight:bold">Fig. 1. LeNet-5</center><br>

<p>Its structure is quite simple from today&#39;s perspective: start with two convolutional and pooling layers and end with three dense layers (the last layer is softmax). However, it pioneered the template of CNN, that is:</p>
<ol>
<li>Start with convolutional and pooling layers to extract features and reduce data dimensionality;</li>
<li>End with dense layers to solve the problems.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of LeNet-5</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Reshape</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x.view((-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))  <span class="comment"># reshape the dimension of input data</span></span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    Reshape(),</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),  <span class="comment"># add padding to get 32*32</span></span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(<span class="number">2</span>),  <span class="comment"># windows of the pooling layer in pytorch do not overlap by default</span></span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">400</span>, <span class="number">120</span>),</span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">AlexNet</a> started the craze for neural networks in 2012, before which, the kernel function and SVM were more powerful in machine learning. The key of kernel function is manual feature extraction. With features, it can calculate their correlation using the kernel function and transform it into a convex optimization problem. After that, SVM will work well by feeding these features to it. It has strong beautiful theorems and can be explained mathematically.</p>
<p>AlexNet is actually a larger LeNet. It improves on LeNet and increases the depth of the neural network:</p>
<ul>
<li>Dropout: control the overfitting of deeper neural networks;</li>
<li>ReLu: make gradients larger;</li>
<li>MaxPooling: make gradients larger and the model easier to train;</li>
<li>ImageNet: larger dataset than Mnist;</li>
<li>Data augmentation: create more samples and reduce the sensitivity of convolutional layers to position.</li>
</ul>
<p>AlexNet changed the way people think about machine learning:</p>
<ul>
<li>Learning features through CNN instead of extracting manually;</li>
<li>Training classifiers (traditional ML methods) together with feature extrators (CNN).</li>
</ul>
<p><img src="/2023/05/14/CommonCNNModels/2.png" alt="2"></p>
<center style="font-size:12px;font-weight:bold">Fig. 2. AlexNet</center><br>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of AlexNet</span></span><br><span class="line"><span class="comment"># size of each image: 224*224</span></span><br><span class="line">Net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">1</span>),  <span class="comment"># the dataset is Mnist, if ImageNet, 1 should be 3</span></span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">6400</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)  <span class="comment"># dataset is Mnist</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<h1 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.1556.pdf">VGG</a> (Visual Geometry Group) encapsulates the convolutional and pooling layers in AlexNet into blocks so that they can be reused and the network will be more standardized.</p>
<p><img src="/2023/05/14/CommonCNNModels/3.png" alt="3"></p>
<center style="font-size:12px;font-weight:bold">Fig. 3. VGG</center><br>

<p>Usually, for each block, the height and width of matrices are halved, and the number of channels is doubled.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of VGG</span></span><br><span class="line"><span class="comment"># size of each image: 224*224</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg_block</span>(<span class="params">num_convs, in_channels, out_channels</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    definition of block.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        num_convs: the number of convolutional layer in this block</span></span><br><span class="line"><span class="string">        in_channels: the number of input channels in the first convolutional layer</span></span><br><span class="line"><span class="string">        out_channels: the number of output channels of the block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        nn.Sequential</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    layers = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">        layers.append(nn.Conv2d(</span><br><span class="line">            in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">        layers.append(nn.ReLU())</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    layers.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">conv_arch = ((<span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg</span>(<span class="params">conv_arch</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    definition of vgg.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        conv_arch: structure of all the blocks, including number of convolutional </span></span><br><span class="line"><span class="string">                   layer of each block and the number of output channels of each block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        the whole VGG network</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    conv_blks = []</span><br><span class="line">    in_channels = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> (num_convs, out_channels) <span class="keyword">in</span> conv_arch:</span><br><span class="line">        conv_blks.append(vgg_block(</span><br><span class="line">            num_convs, in_channels, out_channels))</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        *conv_blks, nn.Flatten(),</span><br><span class="line">        nn.Linear(out_channels * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),  <span class="comment"># 224 / 2^5 = 7</span></span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="NiN"><a href="#NiN" class="headerlink" title="NiN"></a>NiN</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1312.4400.pdf">NiN</a> (Network in Network) follows the block idea of VGG. However, it removes the dense layer completely as the dense layer need too much memory. As an alternative to the dense layer, NiN utilizes the $1\times1$ kernel and ReLU to add nonlinearity to each pixel and uses global average pooling layer to replace the last dense layer, which compute the mean of each input channel. </p>
<blockquote>
<p>The function of global average pooling layer is the same as the last dense layer but it requires less computation. Softmax is realized by loss function CrossEntropy.</p>
</blockquote>
<p><img src="/2023/05/14/CommonCNNModels/4.png" alt="4"></p>
<center style="font-size:12px;font-weight:bold">Fig. 4. NiN</center><br>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of NiN</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nin_block</span>(<span class="params">in_channels, out_channels, kernel_size, strides, padding</span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU())</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nin_block(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, padding=<span class="number">0</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, strides=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># just normalization, we can remove it</span></span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># the number of labels is 10</span></span><br><span class="line">    nin_block(<span class="number">384</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    <span class="comment"># the shape of output is 1x1</span></span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),  <span class="comment"># the number of input channels must be equal to the number of labels</span></span><br><span class="line">    <span class="comment"># turn the 10 labels to a vector</span></span><br><span class="line">    nn.Flatten())</span><br></pre></td></tr></table></figure>

<blockquote>
<p>The global average pooling reduces the complexity of computation but also slows convergence.</p>
</blockquote>
<h1 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.4842.pdf">GoogLeNet</a> inherits the idea of block network, 1x1 convolutional layer, and global average pooling layer in NiN. The most important block in GoogLeNet is Inception block.</p>
<p><img src="/2023/05/14/CommonCNNModels/5.png" alt="5"></p>
<center style="font-size:12px;font-weight:bold">Fig. 5. Inception block(V1)</center><br>

<p>The inception block consists of multiple parallel pathways which <strong>extract different types of features</strong> from the input. Each pathway generates new output channels using all the channels of input data. Different pathways output different number of output channels but keep the shape of each channel the same as the input channel. Usually, the number of output channels is larger than the number of input channels. The output channels of different pathways are concatenated together to form the new input data.</p>
<blockquote>
<p>In the inception block, the <strong>1x1 kernel</strong> is used to merge channels so that the computaion complexity (it is equal to the number of parameters that the neural network can learn) can be reduced while <strong>the blue layer</strong> extract features from the input.</p>
<p>The output size of each pathway is the hyperparameter that can be modified in inception block.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inception block</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(nn.Module):</span><br><span class="line">    <span class="comment"># c1--c4 which may be a list, are the number of output channels of each pathway</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, c1, c2, c3, c4, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__(**kwargs)</span><br><span class="line">        <span class="comment"># pathway1, single 1x1 convolutional layer</span></span><br><span class="line">        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># pathway2，1x1 convolutional layer + 3x3 convolutional layer</span></span><br><span class="line">        self.p2_1 = nn.Conv2d(in_channels, c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p2_2 = nn.Conv2d(c2[<span class="number">0</span>], c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># pathway3，1x1 convolutional layer + 5x5 convolutional layer</span></span><br><span class="line">        self.p3_1 = nn.Conv2d(in_channels, c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p3_2 = nn.Conv2d(c3[<span class="number">0</span>], c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># pathway4，3x3 maxpooling layer + 1x1 convolutional layer</span></span><br><span class="line">        self.p4_1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ReLU add nonlinearity for each layer</span></span><br><span class="line">        p1 = F.relu(self.p1_1(x))</span><br><span class="line">        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))</span><br><span class="line">        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))</span><br><span class="line">        p4 = F.relu(self.p4_2(self.p4_1(x)))</span><br><span class="line">        <span class="comment"># concatenate the output channels (dim 0 is batch size)</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>The entire GoogLeNet uses 9 inception blocks and one global average pooling layer to generate the prediction. However, the global average pooling layer in GoogLeNet doesn&#39;t requires its output size to be equivalent with the number of labels in softmax because there is a dense layer behind it.</p>
<p><img src="/2023/05/14/CommonCNNModels/6.png" alt="6"></p>
<center style="font-size:12px;font-weight:bold">Fig. 6. GoogleNet</center><br>

<p>The whole GoogLeNet can be divided into 5 stages. After each stage, the length and width of the image are halved and the number of channels increases (often doubles). This is a idea followed by many subsequent neural networks. For instance, in the neural network we build below, the output shape of each stage is:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">24</span>, <span class="number">24</span>])  <span class="comment"># the first stage makes the output a quarter</span></span><br><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">192</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">480</span>, <span class="number">6</span>, <span class="number">6</span>])</span><br><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">832</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">1024</span>])</span><br><span class="line">Linear output shape:         torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of GoogLeNet</span></span><br><span class="line">b1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">                   nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b2 = nn.Sequential(nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">                   nn.ReLU(),</span><br><span class="line">                   nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                   nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b3 = nn.Sequential(Inception(<span class="number">192</span>, <span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>),</span><br><span class="line">                   Inception(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b4 = nn.Sequential(Inception(<span class="number">480</span>, <span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">528</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b5 = nn.Sequential(Inception(<span class="number">832</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   Inception(<span class="number">832</span>, <span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">                   nn.Flatten())</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(<span class="number">1024</span>, <span class="number">10</span>))</span><br><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">96</span>, <span class="number">96</span>))</span><br></pre></td></tr></table></figure>
<p>The above is the first version of GoogLeNet. In the subsequent versions, Google made different improvements to the inception block:</p>
<ul>
<li><p>Inception-BN(V2): batch normalization;</p>
</li>
<li><p>Inception-V3: modify the size of kernel;</p>
</li>
<li><p>Inception-V4: use residual connections</p>
</li>
</ul>
<p>Among them, V3 is used more.</p>
<blockquote>
<p>Advantages of GoogLeNet: fewer model parameters and relatively low computational complexity.</p>
</blockquote>
<h2 id="Batch-normalization"><a href="#Batch-normalization" class="headerlink" title="Batch normalization"></a>Batch normalization</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1502.03167.pdf">Batch normalization</a> is a layer that will make the neural network converge faster as it keeps the input of hidden layer more stable. This is how it works:</p>
<p>$$\mathrm{BN}(\mathbf{x}) &#x3D; \boldsymbol{\gamma} \odot \frac{\mathbf{x} - \hat{\boldsymbol{\mu}}_\mathcal{B}}{\hat{\boldsymbol{\sigma}}_\mathcal{B}} + \boldsymbol{\beta}$$</p>
<p>where $\hat{\boldsymbol{\mu}}_\mathcal{B}$ is the mean of small batch $\mathcal{B}$ and $\hat{\boldsymbol{\sigma}}_\mathcal{B}$ is the standard deviation of small batch $\mathcal{B}$. However, we just artificially make the distribution of $\mathbf{x}$ into a standard normal distribution. Therefore, we reserve two learnable parameters for the machine so that it can automatically adjust the distribution of $\mathbf{x}$. And that is scale ($\boldsymbol{\gamma}$) and shift ($\boldsymbol{\beta}$), which adjust variance and mean respectively. They have the same shape as $\mathbf{x}$.</p>
<p>For $\hat{\boldsymbol{\mu}}_\mathcal{B}$, it is easy to compute for each batch:</p>
<p>$$\hat{\boldsymbol{\mu}} _\mathcal{B} &#x3D; \frac{1} {|\mathcal{B} |} \sum _{\mathbf{x} \in \mathcal{B}} \mathbf{ x }$$</p>
<p>But for $\hat{\boldsymbol{\sigma}}_\mathcal{B}$, we should add $\epsilon$ so that the formula don&#39;t divide by 0.</p>
<p>$$\hat{\boldsymbol {\sigma}} _\mathcal{B}^2 &#x3D; \frac{1} {|\mathcal{B} |} \sum _{\mathbf{ x } \in \mathcal{ B }} (\mathbf{x} - \hat{\boldsymbol{\mu}} _{\mathcal{B}})^2 + \epsilon$$</p>
<blockquote>
<p>Usually, we make $\epsilon$ 1e-5 or 1e-6.</p>
</blockquote>
<p>Similar to dropout, we only make the batch normalization layer work when training. When making prediction, we use <strong>global mean</strong> and <strong>global variance</strong> to normalize the input of hiddden layers. The method to get them is slightly similar to that we use to get RTT in computer network:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">moving_mean = momentum * moving_mean + (<span class="number">1.0</span> - momentum) * mean</span><br><span class="line">moving_var = momentum * moving_var + (<span class="number">1.0</span> - momentum) * var</span><br></pre></td></tr></table></figure>
<p>where <code>mean</code> and <code>var</code> are mean and variance the agent get in this small batch, <code>momentum</code> is a weight factor (range from 0 to 1).</p>
<blockquote>
<p>$\boldsymbol{\gamma}$ and $\boldsymbol{\beta}$ are still needed.</p>
</blockquote>
<p>It is important to understand that all the mean and variance the agent computes are mean and variance of each <strong>feature</strong> or <strong>channel</strong> (for the convolutional layer, a channel represents a feature). That&#39;s why the shape of the second dimension of $\boldsymbol{\gamma}$ and $\boldsymbol{\beta}$ is the same as the number of features for dense layers or the number of input channels for convolutional layers.</p>
<blockquote>
<p>We put the batch normalization layer before the activation layer. Its function is a bit like <em>dropout</em> so we often don&#39;t use both layers at the same time.</p>
</blockquote>
<p>It is not clear that why batch normalization works. Some researchers guess that it works as it add noise to each small batch. Those noise make the output of different layers more stable and more realistic. Hence, the gradients of bottom layers will larger and the model converge faster. But it doesn&#39;t change the accuracy of models.</p>
<blockquote>
<p>Xavier makes the initial value of the model parameters more stable. Batch normalization makes the output of hidden layers (or the input of hidden layers) stable. It&#39;s actually a linear layer that modifies the data as we wish. Namely, <strong>we give the agent some human guidance</strong>.</p>
</blockquote>
<h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.03385.pdf">ResNet</a> combined with batch normalization enables us to train a deeper neural network. Before ResNet, the model we train is based on non-nested function classes like the figure on the left. Namely, when we add a new block to complicate the model, we establish a new mapping relationship $y&#x3D;g(f(x))$. However, we can&#39;t make sure that $g(f(x))$ is better than $f(x)$ since $g(f(x))$ can&#39;t cover all the zone that $f(x)$ cover. What&#39;s more, in a deep neural network, the gradients of the bottom layers are usually very small, which makes the bottom layers converge slowly.</p>
<p>The core idea of ResNet is to compute $y&#x3D;g(f(x))+f(x)$ instead of $y&#x3D;g(f(x))$ (Fig. 8). This small change makes a more complex network contain a simpler network (like the picture on the right). Therefore, when using ResNet, a deeper network always performs better than a simple network. In addition, ResNet provides a fast track for the bottom layer to get larger gradients (through $f(x)$). What&#39;s more, when the simple network $f(x)$ has already performed well, its gradients will be rather small, that is, its parameters will not change significantly and it will keep performing well in a deeper network.</p>
<p><img src="/2023/05/14/CommonCNNModels/7.png" alt="7"></p>
<center style="font-size:12px;font-weight:bold">Fig. 7. Non-nested and nested function classes</center><br>

<p><img src="/2023/05/14/CommonCNNModels/8.png" alt="8"></p>
<center style="font-size:12px;font-weight:bold">Fig. 8. Residual block, the weight layer could be dense or convolutional layer</center><br>

<p>The structure of ResNet is similar to GoogLeNet but it replace the inception block with residual block.</p>
<p><img src="/2023/05/14/CommonCNNModels/9.png" alt="9"></p>
<center style="font-size:12px;font-weight:bold">Fig. 9. ResNet-18</center><br>

<blockquote>
<p>When counting the number of layer, we only count the convolutional layer and the dense layer.</p>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/CNN/" rel="tag"># CNN</a>
          </div>
          <script type="text/javascript">
          var tagsall=document.getElementsByClassName("post-tags")
          for (var i = tagsall.length - 1; i >= 0; i--){
            var tags=tagsall[i].getElementsByTagName("a");
            for (var j = tags.length - 1; j >= 0; j--) {
                var r=Math.floor(Math.random()*75+130);
                var g=Math.floor(Math.random()*75+100);
                var b=Math.floor(Math.random()*75+80);
                tags[j].style.background = "rgb("+r+","+g+","+b+")";
            }
          }                        
          </script>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/05/10/FourierTransformAndCNN/" rel="prev" title="Fourier Transform and CNN">
                  <i class="fa fa-angle-left"></i> Fourier Transform and CNN
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/05/19/MultipleGPUsAndParallelism/" rel="next" title="Multiple GPUs and Parallelism">
                  Multiple GPUs and Parallelism <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fas fa-star-of-david"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Chaolv Zeng</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Word count total: </span>
    <span title="Word count total">161k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">9:45</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div><script color="240,255,255" opacity="1" zIndex="-1" count="100" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

<!-- <br /> -->
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<!-- <span id="times">载入时分秒...</span> -->
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("11/17/2022 8:00:00");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); 
        if(String(snum).length ==1 ){snum = "0" + snum;}
        // var times = document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "+hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/fancybox.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":false,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
