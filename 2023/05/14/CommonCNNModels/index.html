<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=[object Object]"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '[object Object]');
</script>
<!-- End Google Analytics -->

  
  <title>Common CNN Models | JourneyToCoding</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Some commonly used CNN models: LeNet-5, AlexNet, VGG, NiN, GoogLeNet, ResNet.">
<meta property="og:type" content="article">
<meta property="og:title" content="Common CNN Models">
<meta property="og:url" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/index.html">
<meta property="og:site_name" content="JourneyToCoding">
<meta property="og:description" content="Some commonly used CNN models: LeNet-5, AlexNet, VGG, NiN, GoogLeNet, ResNet.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/1.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/2.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/3.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/4.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/5.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/6.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/7.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/8.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/9.png">
<meta property="article:published_time" content="2023-05-14T04:33:39.000Z">
<meta property="article:modified_time" content="2023-08-09T05:48:32.000Z">
<meta property="article:author" content="ChaosTsang">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="CNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/1.png">
  
    <link rel="alternate" href="/atom.xml" title="JourneyToCoding" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/%5Bobject%20Object%5D">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">JourneyToCoding</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Code for fun</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/">home</a>
        
          <a class="main-nav-link" href="/about/">about</a>
        
          <a class="main-nav-link" href="/tags/">tags</a>
        
          <a class="main-nav-link" href="/categories/">categories</a>
        
          <a class="main-nav-link" href="/archives/">archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://zclzcl0223.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-CommonCNNModels" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/05/14/CommonCNNModels/" class="article-date">
  <time class="dt-published" datetime="2023-05-14T04:33:39.000Z" itemprop="datePublished">2023-05-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Dive-Into-Deep-Learning/">Dive Into Deep Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Common CNN Models
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <span id="more"></span>

<h1 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h1><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/726791">LeNet-5</a> which was published in 1998, is one of the simplest CNN models. It was originally used to recognize handwritten numbers between 0 and 9.</p>
<p><img src="/2023/05/14/CommonCNNModels/1.png" alt="1"></p>
<center style="font-size:12px;font-weight:bold">Fig. 1. LeNet-5</center><br>

<p>Its structure is quite simple from today&#39;s perspective: start with two convolutional and pooling layers and end with three dense layers (the last layer is softmax). However, it pioneered the template of CNN, that is:</p>
<ol>
<li>Start with convolutional and pooling layers to extract features and reduce data dimensionality;</li>
<li>End with dense layers to solve the problems.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of LeNet-5</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Reshape</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x.view((-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))  <span class="comment"># reshape the dimension of input data</span></span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    Reshape(),</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),  <span class="comment"># add padding to get 32*32</span></span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(<span class="number">2</span>),  <span class="comment"># windows of the pooling layer in pytorch do not overlap by default</span></span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">400</span>, <span class="number">120</span>),</span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">AlexNet</a> started the craze for neural networks in 2012, before which, the kernel function and SVM were more powerful in machine learning. The key of kernel function is manual feature extraction. With features, it can calculate their correlation using the kernel function and transform it into a convex optimization problem. After that, SVM will work well by feeding these features to it. It has strong beautiful theorems and can be explained mathematically.</p>
<p>AlexNet is actually a larger LeNet. It improves on LeNet and increases the depth of the neural network:</p>
<ul>
<li>Dropout: control the overfitting of deeper neural networks;</li>
<li>ReLu: make gradients larger;</li>
<li>MaxPooling: make gradients larger and the model easier to train;</li>
<li>ImageNet: larger dataset than Mnist;</li>
<li>Data augmentation: create more samples and reduce the sensitivity of convolutional layers to position.</li>
</ul>
<p>AlexNet changed the way people think about machine learning:</p>
<ul>
<li>Learning features through CNN instead of extracting manually;</li>
<li>Training classifiers (traditional ML methods) together with feature extrators (CNN).</li>
</ul>
<p><img src="/2023/05/14/CommonCNNModels/2.png" alt="2"></p>
<center style="font-size:12px;font-weight:bold">Fig. 2. AlexNet</center><br>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of AlexNet</span></span><br><span class="line"><span class="comment"># size of each image: 224*224</span></span><br><span class="line">Net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">1</span>),  <span class="comment"># the dataset is Mnist, if ImageNet, 1 should be 3</span></span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">6400</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)  <span class="comment"># dataset is Mnist</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<h1 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.1556.pdf">VGG</a> (Visual Geometry Group) encapsulates the convolutional and pooling layers in AlexNet into blocks so that they can be reused and the network will be more standardized.</p>
<p><img src="/2023/05/14/CommonCNNModels/3.png" alt="3"></p>
<center style="font-size:12px;font-weight:bold">Fig. 3. VGG</center><br>

<p>Usually, for each block, the height and width of matrices are halved, and the number of channels is doubled.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of VGG</span></span><br><span class="line"><span class="comment"># size of each image: 224*224</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg_block</span>(<span class="params">num_convs, in_channels, out_channels</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    definition of block.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        num_convs: the number of convolutional layer in this block</span></span><br><span class="line"><span class="string">        in_channels: the number of input channels in the first convolutional layer</span></span><br><span class="line"><span class="string">        out_channels: the number of output channels of the block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        nn.Sequential</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    layers = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">        layers.append(nn.Conv2d(</span><br><span class="line">            in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">        layers.append(nn.ReLU())</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    layers.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">conv_arch = ((<span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg</span>(<span class="params">conv_arch</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    definition of vgg.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        conv_arch: structure of all the blocks, including number of convolutional </span></span><br><span class="line"><span class="string">                   layer of each block and the number of output channels of each block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        the whole VGG network</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    conv_blks = []</span><br><span class="line">    in_channels = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> (num_convs, out_channels) <span class="keyword">in</span> conv_arch:</span><br><span class="line">        conv_blks.append(vgg_block(</span><br><span class="line">            num_convs, in_channels, out_channels))</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        *conv_blks, nn.Flatten(),</span><br><span class="line">        nn.Linear(out_channels * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),  <span class="comment"># 224 / 2^5 = 7</span></span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="NiN"><a href="#NiN" class="headerlink" title="NiN"></a>NiN</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1312.4400.pdf">NiN</a> (Network in Network) follows the block idea of VGG. However, it removes the dense layer completely as the dense layer need too much memory. As an alternative to the dense layer, NiN utilizes the $1\times1$ kernel and ReLU to add nonlinearity to each pixel and uses global average pooling layer to replace the last dense layer, which compute the mean of each input channel. </p>
<blockquote>
<p>The function of global average pooling layer is the same as the last dense layer but it requires less computation. Softmax is realized by loss function CrossEntropy.</p>
</blockquote>
<p><img src="/2023/05/14/CommonCNNModels/4.png" alt="4"></p>
<center style="font-size:12px;font-weight:bold">Fig. 4. NiN</center><br>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of NiN</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nin_block</span>(<span class="params">in_channels, out_channels, kernel_size, strides, padding</span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU())</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nin_block(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, padding=<span class="number">0</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, strides=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># just normalization, we can remove it</span></span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># the number of labels is 10</span></span><br><span class="line">    nin_block(<span class="number">384</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    <span class="comment"># the shape of output is 1x1</span></span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),  <span class="comment"># the number of input channels must be equal to the number of labels</span></span><br><span class="line">    <span class="comment"># turn the 10 labels to a vector</span></span><br><span class="line">    nn.Flatten())</span><br></pre></td></tr></table></figure>

<blockquote>
<p>The global average pooling reduces the complexity of computation but also slows convergence.</p>
</blockquote>
<h1 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.4842.pdf">GoogLeNet</a> inherits the idea of block network, 1x1 convolutional layer, and global average pooling layer in NiN. The most important block in GoogLeNet is Inception block.</p>
<p><img src="/2023/05/14/CommonCNNModels/5.png" alt="5"></p>
<center style="font-size:12px;font-weight:bold">Fig. 5. Inception block(V1)</center><br>

<p>The inception block consists of multiple parallel pathways which <strong>extract different types of features</strong> from the input. Each pathway generates new output channels using all the channels of input data. Different pathways output different number of output channels but keep the shape of each channel the same as the input channel. Usually, the number of output channels is larger than the number of input channels. The output channels of different pathways are concatenated together to form the new input data.</p>
<blockquote>
<p>In the inception block, the <strong>1x1 kernel</strong> is used to merge channels so that the computaion complexity (it is equal to the number of parameters that the neural network can learn) can be reduced while <strong>the blue layer</strong> extract features from the input.</p>
<p>The output size of each pathway is the hyperparameter that can be modified in inception block.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inception block</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(nn.Module):</span><br><span class="line">    <span class="comment"># c1--c4 which may be a list, are the number of output channels of each pathway</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, c1, c2, c3, c4, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__(**kwargs)</span><br><span class="line">        <span class="comment"># pathway1, single 1x1 convolutional layer</span></span><br><span class="line">        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># pathway2，1x1 convolutional layer + 3x3 convolutional layer</span></span><br><span class="line">        self.p2_1 = nn.Conv2d(in_channels, c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p2_2 = nn.Conv2d(c2[<span class="number">0</span>], c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># pathway3，1x1 convolutional layer + 5x5 convolutional layer</span></span><br><span class="line">        self.p3_1 = nn.Conv2d(in_channels, c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.p3_2 = nn.Conv2d(c3[<span class="number">0</span>], c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># pathway4，3x3 maxpooling layer + 1x1 convolutional layer</span></span><br><span class="line">        self.p4_1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ReLU add nonlinearity for each layer</span></span><br><span class="line">        p1 = F.relu(self.p1_1(x))</span><br><span class="line">        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))</span><br><span class="line">        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))</span><br><span class="line">        p4 = F.relu(self.p4_2(self.p4_1(x)))</span><br><span class="line">        <span class="comment"># concatenate the output channels (dim 0 is batch size)</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>The entire GoogLeNet uses 9 inception blocks and one global average pooling layer to generate the prediction. However, the global average pooling layer in GoogLeNet doesn&#39;t requires its output size to be equivalent with the number of labels in softmax because there is a dense layer behind it.</p>
<p><img src="/2023/05/14/CommonCNNModels/6.png" alt="6"></p>
<center style="font-size:12px;font-weight:bold">Fig. 6. GoogleNet</center><br>

<p>The whole GoogLeNet can be divided into 5 stages. After each stage, the length and width of the image are halved and the number of channels increases (often doubles). This is a idea followed by many subsequent neural networks. For instance, in the neural network we build below, the output shape of each stage is:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">64</span>, <span class="number">24</span>, <span class="number">24</span>])  <span class="comment"># the first stage makes the output a quarter</span></span><br><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">192</span>, <span class="number">12</span>, <span class="number">12</span>])</span><br><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">480</span>, <span class="number">6</span>, <span class="number">6</span>])</span><br><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">832</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">Sequential output shape:     torch.Size([<span class="number">1</span>, <span class="number">1024</span>])</span><br><span class="line">Linear output shape:         torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure of GoogLeNet</span></span><br><span class="line">b1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">                   nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b2 = nn.Sequential(nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">                   nn.ReLU(),</span><br><span class="line">                   nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                   nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b3 = nn.Sequential(Inception(<span class="number">192</span>, <span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>),</span><br><span class="line">                   Inception(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b4 = nn.Sequential(Inception(<span class="number">480</span>, <span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">512</span>, <span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">                   Inception(<span class="number">528</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b5 = nn.Sequential(Inception(<span class="number">832</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   Inception(<span class="number">832</span>, <span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">                   nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">                   nn.Flatten())</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(<span class="number">1024</span>, <span class="number">10</span>))</span><br><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">96</span>, <span class="number">96</span>))</span><br></pre></td></tr></table></figure>
<p>The above is the first version of GoogLeNet. In the subsequent versions, Google made different improvements to the inception block:</p>
<ul>
<li><p>Inception-BN(V2): batch normalization;</p>
</li>
<li><p>Inception-V3: modify the size of kernel;</p>
</li>
<li><p>Inception-V4: use residual connections</p>
</li>
</ul>
<p>Among them, V3 is used more.</p>
<blockquote>
<p>Advantages of GoogLeNet: fewer model parameters and relatively low computational complexity.</p>
</blockquote>
<h2 id="Batch-normalization"><a href="#Batch-normalization" class="headerlink" title="Batch normalization"></a>Batch normalization</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1502.03167.pdf">Batch normalization</a> is a layer that will make the neural network converge faster as it keeps the input of hidden layer more stable. This is how it works:</p>
<p>$$\mathrm{BN}(\mathbf{x}) &#x3D; \boldsymbol{\gamma} \odot \frac{\mathbf{x} - \hat{\boldsymbol{\mu}}_\mathcal{B}}{\hat{\boldsymbol{\sigma}}_\mathcal{B}} + \boldsymbol{\beta}$$</p>
<p>where $\hat{\boldsymbol{\mu}}_\mathcal{B}$ is the mean of small batch $\mathcal{B}$ and $\hat{\boldsymbol{\sigma}}_\mathcal{B}$ is the standard deviation of small batch $\mathcal{B}$. However, we just artificially make the distribution of $\mathbf{x}$ into a standard normal distribution. Therefore, we reserve two learnable parameters for the machine so that it can automatically adjust the distribution of $\mathbf{x}$. And that is scale ($\boldsymbol{\gamma}$) and shift ($\boldsymbol{\beta}$), which adjust variance and mean respectively. They have the same shape as $\mathbf{x}$.</p>
<p>For $\hat{\boldsymbol{\mu}}_\mathcal{B}$, it is easy to compute for each batch:</p>
<p>$$\hat{\boldsymbol{\mu}} _\mathcal{B} &#x3D; \frac{1} {|\mathcal{B} |} \sum _{\mathbf{x} \in \mathcal{B}} \mathbf{ x }$$</p>
<p>But for $\hat{\boldsymbol{\sigma}}_\mathcal{B}$, we should add $\epsilon$ so that the formula don&#39;t divide by 0.</p>
<p>$$\hat{\boldsymbol {\sigma}} _\mathcal{B}^2 &#x3D; \frac{1} {|\mathcal{B} |} \sum _{\mathbf{ x } \in \mathcal{ B }} (\mathbf{x} - \hat{\boldsymbol{\mu}} _{\mathcal{B}})^2 + \epsilon$$</p>
<blockquote>
<p>Usually, we make $\epsilon$ 1e-5 or 1e-6.</p>
</blockquote>
<p>Similar to dropout, we only make the batch normalization layer work when training. When making prediction, we use <strong>global mean</strong> and <strong>global variance</strong> to normalize the input of hiddden layers. The method to get them is slightly similar to that we use to get RTT in computer network:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">moving_mean = momentum * moving_mean + (<span class="number">1.0</span> - momentum) * mean</span><br><span class="line">moving_var = momentum * moving_var + (<span class="number">1.0</span> - momentum) * var</span><br></pre></td></tr></table></figure>
<p>where <code>mean</code> and <code>var</code> are mean and variance the agent get in this small batch, <code>momentum</code> is a weight factor (range from 0 to 1).</p>
<blockquote>
<p>$\boldsymbol{\gamma}$ and $\boldsymbol{\beta}$ are still needed.</p>
</blockquote>
<p>It is important to understand that all the mean and variance the agent computes are mean and variance of each <strong>feature</strong> or <strong>channel</strong> (for the convolutional layer, a channel represents a feature). That&#39;s why the shape of the second dimension of $\boldsymbol{\gamma}$ and $\boldsymbol{\beta}$ is the same as the number of features for dense layers or the number of input channels for convolutional layers.</p>
<blockquote>
<p>We put the batch normalization layer before the activation layer. Its function is a bit like <em>dropout</em> so we often don&#39;t use both layers at the same time.</p>
</blockquote>
<p>It is not clear that why batch normalization works. Some researchers guess that it works as it add noise to each small batch. Those noise make the output of different layers more stable and more realistic. Hence, the gradients of bottom layers will larger and the model converge faster. But it doesn&#39;t change the accuracy of models.</p>
<blockquote>
<p>Xavier makes the initial value of the model parameters more stable. Batch normalization makes the output of hidden layers (or the input of hidden layers) stable. It&#39;s actually a linear layer that modifies the data as we wish. Namely, <strong>we give the agent some human guidance</strong>.</p>
</blockquote>
<h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.03385.pdf">ResNet</a> combined with batch normalization enables us to train a deeper neural network. Before ResNet, the model we train is based on non-nested function classes like the figure on the left. Namely, when we add a new block to complicate the model, we establish a new mapping relationship $y&#x3D;g(f(x))$. However, we can&#39;t make sure that $g(f(x))$ is better than $f(x)$ since $g(f(x))$ can&#39;t cover all the zone that $f(x)$ cover. What&#39;s more, in a deep neural network, the gradients of the bottom layers are usually very small, which makes the bottom layers converge slowly.</p>
<p>The core idea of ResNet is to compute $y&#x3D;g(f(x))+f(x)$ instead of $y&#x3D;g(f(x))$ (Fig. 8). This small change makes a more complex network contain a simpler network (like the picture on the right). Therefore, when using ResNet, a deeper network always performs better than a simple network. In addition, ResNet provides a fast track for the bottom layer to get larger gradients (through $f(x)$). What&#39;s more, when the simple network $f(x)$ has already performed well, its gradients will be rather small, that is, its parameters will not change significantly and it will keep performing well in a deeper network.</p>
<p><img src="/2023/05/14/CommonCNNModels/7.png" alt="7"></p>
<center style="font-size:12px;font-weight:bold">Fig. 7. Non-nested and nested function classes</center><br>

<p><img src="/2023/05/14/CommonCNNModels/8.png" alt="8"></p>
<center style="font-size:12px;font-weight:bold">Fig. 8. Residual block, the weight layer could be dense or convolutional layer</center><br>

<p>The structure of ResNet is similar to GoogLeNet but it replace the inception block with residual block.</p>
<p><img src="/2023/05/14/CommonCNNModels/9.png" alt="9"></p>
<center style="font-size:12px;font-weight:bold">Fig. 9. ResNet-18</center><br>

<blockquote>
<p>When counting the number of layer, we only count the convolutional layer and the dense layer.</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zclzcl0223.github.io/2023/05/14/CommonCNNModels/" data-id="clzik0lbz000jv47k4izh1mm2" data-title="Common CNN Models" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/05/19/MultipleGPUsAndParallelism/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Multiple GPUs and Parallelism
        
      </div>
    </a>
  
  
    <a href="/2023/05/10/FourierTransformAndCNN/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Fourier Transform and CNN</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Advanced-Model/">Advanced Model</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS7313-Computational-Complexity/">CS7313: Computational Complexity</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Configuration/">Configuration</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Dive-Into-Deep-Learning/">Dive Into Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GNN/">GNN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kernel-Method/">Kernel Method</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MATH6005-Matrix-Theory/">MATH6005: Matrix Theory</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning-by-AndrewNg/">Machine Learning by AndrewNg</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/">Paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming-Language/">Programming Language</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tool/">Tool</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Attention-Mechanism/" rel="tag">Attention Mechanism</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Configuration/" rel="tag">Configuration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Analysis/" rel="tag">Data Analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dataset-Distillation/" rel="tag">Dataset Distillation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Trees/" rel="tag">Decision Trees</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GCN/" rel="tag">GCN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GNN/" rel="tag">GNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Generative-AI/" rel="tag">Generative AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/" rel="tag">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lab/" rel="tag">Lab</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markup-Language/" rel="tag">Markup Language</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Paper/" rel="tag">Paper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Recommender-System/" rel="tag">Recommender System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reinforcement-Learning/" rel="tag">Reinforcement Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Supervised-Learning/" rel="tag">Supervised Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Theoretical-Computer-Science/" rel="tag">Theoretical Computer Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/" rel="tag">Tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Unsupervised-Learning/" rel="tag">Unsupervised Learning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Attention-Mechanism/" style="font-size: 11.82px;">Attention Mechanism</a> <a href="/tags/CNN/" style="font-size: 12.73px;">CNN</a> <a href="/tags/Configuration/" style="font-size: 10px;">Configuration</a> <a href="/tags/Data-Analysis/" style="font-size: 10px;">Data Analysis</a> <a href="/tags/Dataset-Distillation/" style="font-size: 13.64px;">Dataset Distillation</a> <a href="/tags/Decision-Trees/" style="font-size: 10px;">Decision Trees</a> <a href="/tags/Deep-Learning/" style="font-size: 20px;">Deep Learning</a> <a href="/tags/GCN/" style="font-size: 11.82px;">GCN</a> <a href="/tags/GNN/" style="font-size: 15.45px;">GNN</a> <a href="/tags/Generative-AI/" style="font-size: 10.91px;">Generative AI</a> <a href="/tags/Hexo/" style="font-size: 10.91px;">Hexo</a> <a href="/tags/Lab/" style="font-size: 10.91px;">Lab</a> <a href="/tags/Linux/" style="font-size: 16.36px;">Linux</a> <a href="/tags/Machine-Learning/" style="font-size: 17.27px;">Machine Learning</a> <a href="/tags/Markup-Language/" style="font-size: 10px;">Markup Language</a> <a href="/tags/Math/" style="font-size: 19.09px;">Math</a> <a href="/tags/Paper/" style="font-size: 14.55px;">Paper</a> <a href="/tags/Python/" style="font-size: 18.18px;">Python</a> <a href="/tags/RNN/" style="font-size: 10.91px;">RNN</a> <a href="/tags/Recommender-System/" style="font-size: 10.91px;">Recommender System</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 10.91px;">Reinforcement Learning</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/Supervised-Learning/" style="font-size: 11.82px;">Supervised Learning</a> <a href="/tags/Theoretical-Computer-Science/" style="font-size: 15.45px;">Theoretical Computer Science</a> <a href="/tags/Tool/" style="font-size: 18.18px;">Tool</a> <a href="/tags/Unsupervised-Learning/" style="font-size: 11.82px;">Unsupervised Learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/06/17/Diffusion/">Diffusion</a>
          </li>
        
          <li>
            <a href="/2024/01/20/VAE/">VAE</a>
          </li>
        
          <li>
            <a href="/2023/12/02/CountingComplexity/">Computational Complexity: Complexity of Counting</a>
          </li>
        
          <li>
            <a href="/2023/11/24/MatrixTheory5/">MatrixTheory: 特殊矩阵与矩阵分解</a>
          </li>
        
          <li>
            <a href="/2023/11/13/RandomizedComputation/">Computational Complexity: Randomized Computation</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 ChaosTsang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/" class="mobile-nav-link">home</a>
  
    <a href="/about/" class="mobile-nav-link">about</a>
  
    <a href="/tags/" class="mobile-nav-link">tags</a>
  
    <a href="/categories/" class="mobile-nav-link">categories</a>
  
    <a href="/archives/" class="mobile-nav-link">archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>





<script src="/js/script.js"></script>





  </div>
</body>
</html>