<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zclzcl0223.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12,"onmobile":false},"hljswrap":true,"copycode":{"enable":true,"style":"mac","show_result":false},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="CNN is good at processing spatial information but it is not good at processing sequence information. RNN (Recurrent Neural Network) can better process sequence information than other neural networks.">
<meta property="og:type" content="article">
<meta property="og:title" content="RNN: a Special Kind of MLP">
<meta property="og:url" content="https://zclzcl0223.github.io/2023/05/25/RNN/index.html">
<meta property="og:site_name" content="JourneyToCoding">
<meta property="og:description" content="CNN is good at processing spatial information but it is not good at processing sequence information. RNN (Recurrent Neural Network) can better process sequence information than other neural networks.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/25/RNN/1.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/25/RNN/2.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/25/RNN/3.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/25/RNN/4.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/25/RNN/5.png">
<meta property="article:published_time" content="2023-05-25T09:27:35.000Z">
<meta property="article:modified_time" content="2023-08-09T05:58:00.000Z">
<meta property="article:author" content="Chaolv Zeng">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="RNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zclzcl0223.github.io/2023/05/25/RNN/1.png">


<link rel="canonical" href="https://zclzcl0223.github.io/2023/05/25/RNN/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://zclzcl0223.github.io/2023/05/25/RNN/","path":"2023/05/25/RNN/","title":"RNN: a Special Kind of MLP"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>RNN: a Special Kind of MLP | JourneyToCoding</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <a target="_blank" rel="noopener" href="https://github.com/zclzcl0223" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">JourneyToCoding</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Code for Fun</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Sequence-model-amp-Language-model"><span class="nav-number">1.</span> <span class="nav-text">Sequence model &amp; Language model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Markov-assumption"><span class="nav-number">1.1.</span> <span class="nav-text">Markov assumption</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Latent-autoregressive-models"><span class="nav-number">1.2.</span> <span class="nav-text">Latent autoregressive models</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Language-models"><span class="nav-number">1.3.</span> <span class="nav-text">Language models</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RNN"><span class="nav-number">2.</span> <span class="nav-text">RNN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Gradient-clipping"><span class="nav-number">2.1.</span> <span class="nav-text">Gradient clipping</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Perplexity"><span class="nav-number">2.2.</span> <span class="nav-text">Perplexity</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Structure-of-RNN"><span class="nav-number">3.</span> <span class="nav-text">Structure of RNN</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Chaolv Zeng"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Chaolv Zeng</p>
  <div class="site-description" itemprop="description">Start of Something New</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">106</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zclzcl0223" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zclzcl0223" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chaostsang0223@gmail.com" title="E-Mail → mailto:chaostsang0223@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="sidebar-inner sidebar-post-related">
          <div class="animated">
              <div class="links-of-blogroll-title"><i class="fa fa-signs-post fa-fw"></i>
    Related Posts
  </div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/05/29/CommonRNNModels/" rel="bookmark">
        <time class="popular-posts-time">2023-05-29</time>
        <br>
      Common RNN Models
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/05/31/EncoderDecoder/" rel="bookmark">
        <time class="popular-posts-time">2023-05-31</time>
        <br>
      The Encoder-Decoder Architecture
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/06/07/Transformer/" rel="bookmark">
        <time class="popular-posts-time">2023-06-07</time>
        <br>
      Transformer: Self-Attention and Parallelization
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/05/19/MultipleGPUsAndParallelism/" rel="bookmark">
        <time class="popular-posts-time">2023-05-19</time>
        <br>
      Multiple GPUs and Parallelism
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2023/06/06/Attention/" rel="bookmark">
        <time class="popular-posts-time">2023-06-06</time>
        <br>
      Attention Mechanisms: More Targeted Information Extraction
      </a>
    </li>
  </ul>

          </div>
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zclzcl0223.github.io/2023/05/25/RNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chaolv Zeng">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JourneyToCoding">
      <meta itemprop="description" content="Start of Something New">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="RNN: a Special Kind of MLP | JourneyToCoding">
      <meta itemprop="description" content="CNN is good at processing spatial information but it is not good at processing sequence information. RNN (Recurrent Neural Network) can better process sequence information than other neural networks.">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          RNN: a Special Kind of MLP
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-05-25 17:27:35" itemprop="dateCreated datePublished" datetime="2023-05-25T17:27:35+08:00">2023-05-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-08-09 13:58:00" itemprop="dateModified" datetime="2023-08-09T13:58:00+08:00">2023-08-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Dive-Into-Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Dive Into Deep Learning</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>1.2k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>4 mins.</span>
    </span>
</div>

            <div class="post-description">CNN is good at processing spatial information but it is not good at processing sequence information. RNN (Recurrent Neural Network) can better process sequence information than other neural networks.</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><span id="more"></span>

<h1 id="Sequence-model-amp-Language-model"><a href="#Sequence-model-amp-Language-model" class="headerlink" title="Sequence model &amp; Language model"></a>Sequence model &amp; Language model</h1><p>Sequence information is the data arranged in a certain order, whose biggest feature is contexutal correlation. Language, or text, is typical sequence information. When dealing with sequence information, what the neural network does is to predict the future based on the history, that is:</p>
<p>$$x_t\sim P(x_t|x_1,...,x _{t-1})$$</p>
<p>where $x_t$ is correlated with its history $(x_1,...,x _{t-1})$. Similarly, if we wanna predict a new sequence, we deal with:</p>
<p>$$(x_1,...,x_T)\sim \prod\limits_{t&#x3D;1}^TP(x_t|x_1,...,x _{t-1})$$</p>
<p>Such a model or such a relationship is called sequence model. In sequence model, the data is not independent but sequential. We use previous data to predict future data. However, when the sequence is extremely long, the quantity of previous data will be rather large. In general, there are two methods to cope with it.</p>
<h2 id="Markov-assumption"><a href="#Markov-assumption" class="headerlink" title="Markov assumption"></a>Markov assumption</h2><p>Markov assumption (or Markov model) assumes that the future $x_t$ is only correlated with a small span of the past $(x _{t-1},...,x _{t-\tau})$ where $\tau$ is the span. In this case:</p>
<p>$$x_t\sim P(x_t|x_{t-\tau},...,x _{t-1})$$</p>
<p>$\tau$ is an import hyperparameter that determines the complexity of prediction. When $\tau&#x3D;m$, the model is called <em>mth-order Markov model</em>:</p>
<p>$$(x_1,...,x_T)\sim \prod\limits_{t&#x3D;1}^TP(x_t|x _{\max (t-\tau,0)},...,x _{t-1})$$</p>
<p>where $x_0$ has nothing to do with $x_i$, that is, it is independent from others. Such a model is also called <em>Autoregressive model</em>.</p>
<h2 id="Latent-autoregressive-models"><a href="#Latent-autoregressive-models" class="headerlink" title="Latent autoregressive models"></a>Latent autoregressive models</h2><p>In this model, we use a new parameter $h_t$ to summarize the past information:</p>
<p>$$h_t&#x3D;g(h_{t-1},x_{t-1})$$</p>
<p>$$\hat{x}_t&#x3D;P(x_t|h_t)$$</p>
<p>where $h_t$ is the latent variable.</p>
<p><img src="/2023/05/25/RNN/1.png" alt="1"></p>
<center style="font-size:12px; font-weight:bold">Fig. 1. Latent autoregressive models</center><br>

<blockquote>
<p>In a word, $(x _{t-\tau},...,x _{t-1})$ is the feature of $x_t$. The aim of RNN is to obtain the mapping relation $x_t&#x3D;f(x _{t-\tau},...,x _{t-1})$ for markov models or $h_t&#x3D;g(h _{t-1},x _{t-1})$ and $\hat{x}_t&#x3D;f(h_t)$ for latent autoregressive models.</p>
</blockquote>
<h2 id="Language-models"><a href="#Language-models" class="headerlink" title="Language models"></a>Language models</h2><p>The language model is a typical sequence model. However, because languages are in the form of <em>string</em>, it is extremely hard for computers to cope with them. Hence, we always divide a text into several <em>tokens</em>. A token is a string and a word in the original text. Then, we count the probablity of occurrence of all tokens or token sequences and use markov models to model language models. The value of $\tau$ decides the number of tokens we take into account to predict $x_t$. For instance, one token (tokens are independent from each other) is <em>Unigram</em>, two tokens are <em>Bigram</em> and three tokens are <em>Trigram</em>.</p>
<blockquote>
<p>One-hot encoding is used to turn a token into a vector so that the neural network can work.</p>
</blockquote>
<h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p>RNNs (recurrent neural networks) are neural networks with <em>hidden state</em> which is another <em>input</em> of the hidden layer and is updated by calling the hidden layer recurrrently. </p>
<p><img src="/2023/05/25/RNN/2.png" alt="2"></p>
<center style="font-size:12px; font-weight:bold">Fig. 2. Hidden state</center><br>

<p>The hidden state <em>H</em> is actually the same as input <em>X</em>, that is, they are both inputs of hidden layer:</p>
<p>$$\text{Output}_t&#x3D;H_t&#x3D;\phi(X _tW _{xh}+H _{t-1}W _{hh}+b_h)$$</p>
<p>The following picture shows the nature of RNN better:</p>
<p><img src="/2023/05/25/RNN/3.png" alt="3"></p>
<center style="font-size:12px; font-weight:bold">Fig. 3. CNN</center><br>

<p>In each timing, a token or other sequential unit $X_t$ enters the RNN as an input. $H_{t-1}$ records the information of previous tokens. They together produce $H_t$. $H_t$ records the information of current token $X_t$ and previous tokens. Hence, it is only the output of this hidden layer at this timing but also the input of the hidden layer at the next timing. That&#39;s why such a neural network is called RNN: for a sequence with several tokens, all the tokens will be fed to RNN in sequence. Their relationship is recorded by $H$. The updated $H$ is fed to RNN recurrently. And finally, after dealing with the last token, the prediction is made.</p>
<p><img src="/2023/05/25/RNN/4.png" alt="4"></p>
<center style="font-size:12px; font-weight:bold">Fig. 4. Process of RNN</center><br>

<blockquote>
<p>Though we use the RNN layer several times (depends on the length of sequence) to generate $H_1,...,H_t$ in a single iteration, it is still a layer. Namely, during one iteration, $W_{xh}$, $W_{hh}$ and $b_h$ keep the same. What changes is $H$.</p>
</blockquote>
<p>When the batch is generated by random sampling, that is, the sequence of different batches is not continuous (e.g. batch1: [1, 2], batch2: [8, 9]), $H$ must be initialized to 0 in each iteration. Otherwise (e.g. batch1: [1, 2], batch2: [3, 4]), $H$ should be kept as the last result of the former batch. By doing so, the current batch and the former batch form a longer sequence. In practice, we use random sampling more as the text we cope with is often too long to remember all of it only using $H$.</p>
<blockquote>
<p>The api of RNN in PyTorch is <code>nn.RNN</code> .</p>
</blockquote>
<h2 id="Gradient-clipping"><a href="#Gradient-clipping" class="headerlink" title="Gradient clipping"></a>Gradient clipping</h2><p>Timesteps represent the length of a sequence or $\tau$ in markov assumption. The larger the timestep is, the more information the RNN need to remember. In addition, because the operation of a RNN hidden layer of k timesteps is equivalent to the operation of k dense layers, it is more likely for RNN to have gradient explosion.</p>
<p>To solve this, what we use is gradient clipping. For all the parameters that require gradient, we put their gradient in $\mathbf{g}$ and project $\mathbf{g}$ back to a sphere of given radius $\theta$:</p>
<p>$$\mathbf{g}\leftarrow\min(1,\frac{\theta}{\left|\mathbf{g}\right|})\mathbf{g}$$</p>
<p>Usually, $\theta$ is 5.</p>
<h2 id="Perplexity"><a href="#Perplexity" class="headerlink" title="Perplexity"></a>Perplexity</h2><p>When coping with language model using RNN, what we actually do is to make the agent choose the best token from vocabulary. This is actually a softmax regression problem. However, in NLP, we don&#39;t use the average of crossentropy loss to measure its precision. Instead, we use its exponent, <em>perplexity</em>:</p>
<p>$$\exp(-\frac{1}{n}\sum\limits_{t&#x3D;1}^n\log P(x_t|x_{t-1},...,x_1))$$</p>
<p>They are actually the same but <em>perplexity</em> shows the range of tokens that the agent can choose. Namely, when <em>perplexity</em> is 1, which means that the agent can choose a specific token without hesitation, this is the ideal result. When <em>perlexity</em> is bigger than 1, this means that there are still some tokens confusing the agent.</p>
<h1 id="Structure-of-RNN"><a href="#Structure-of-RNN" class="headerlink" title="Structure of RNN"></a>Structure of RNN</h1><p>There are many types of RNN structure. Different structures are suitable for different functions. For instance, in NLP, one to many structure is suitable for text generation, that is, predicting the subsequent text using current text. Many to one structure is suitable for text categorization. It tries to remember the whole text and only output one value. Many to many structure is fit for machine translation and question answering. Seq2seq is a typical many to many model.</p>
<p><img src="/2023/05/25/RNN/5.png" alt="5"></p>
<center style="font-size:12px; font-weight:bold">Fig. 5. Different structures of RNN</center><br>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/RNN/" rel="tag"># RNN</a>
          </div>
          <script type="text/javascript">
          var tagsall=document.getElementsByClassName("post-tags")
          for (var i = tagsall.length - 1; i >= 0; i--){
            var tags=tagsall[i].getElementsByTagName("a");
            for (var j = tags.length - 1; j >= 0; j--) {
                var r=Math.floor(Math.random()*75+130);
                var g=Math.floor(Math.random()*75+100);
                var b=Math.floor(Math.random()*75+80);
                tags[j].style.background = "rgb("+r+","+g+","+b+")";
            }
          }                        
          </script>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/05/19/MultipleGPUsAndParallelism/" rel="prev" title="Multiple GPUs and Parallelism">
                  <i class="fa fa-angle-left"></i> Multiple GPUs and Parallelism
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/05/29/CommonRNNModels/" rel="next" title="Common RNN Models">
                  Common RNN Models <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2026</span>
    <span class="with-love">
      <i class="fas fa-star-of-david"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Chaolv Zeng</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Word count total: </span>
    <span title="Word count total">163k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">9:51</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div><script color="240,255,255" opacity="1" zIndex="-1" count="100" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

<!-- <br /> -->
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<!-- <span id="times">载入时分秒...</span> -->
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("11/17/2022 8:00:00");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); 
        if(String(snum).length ==1 ){snum = "0" + snum;}
        // var times = document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "+hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/fancybox.js"></script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":false,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
