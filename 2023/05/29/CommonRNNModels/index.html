<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=[object Object]"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '[object Object]');
</script>
<!-- End Google Analytics -->

  
  <title>Common RNN Models | JourneyToCoding</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Some commonly used RNN models: GRU, LSTM, DRNN, BRNN...">
<meta property="og:type" content="article">
<meta property="og:title" content="Common RNN Models">
<meta property="og:url" content="https://zclzcl0223.github.io/2023/05/29/CommonRNNModels/index.html">
<meta property="og:site_name" content="JourneyToCoding">
<meta property="og:description" content="Some commonly used RNN models: GRU, LSTM, DRNN, BRNN...">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/29/CommonRNNModels/1.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/29/CommonRNNModels/2.png">
<meta property="og:image" content="https://zclzcl0223.github.io/2023/05/29/CommonRNNModels/3.png">
<meta property="article:published_time" content="2023-05-29T11:53:15.000Z">
<meta property="article:modified_time" content="2023-08-09T05:51:46.000Z">
<meta property="article:author" content="ChaosTsang">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="RNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zclzcl0223.github.io/2023/05/29/CommonRNNModels/1.png">
  
    <link rel="alternate" href="/atom.xml" title="JourneyToCoding" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/%5Bobject%20Object%5D">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">JourneyToCoding</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Code for fun</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/">home</a>
        
          <a class="main-nav-link" href="/about/">about</a>
        
          <a class="main-nav-link" href="/tags/">tags</a>
        
          <a class="main-nav-link" href="/categories/">categories</a>
        
          <a class="main-nav-link" href="/archives/">archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://zclzcl0223.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-CommonRNNModels" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/05/29/CommonRNNModels/" class="article-date">
  <time class="dt-published" datetime="2023-05-29T11:53:15.000Z" itemprop="datePublished">2023-05-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Dive-Into-Deep-Learning/">Dive Into Deep Learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Common RNN Models
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <span id="more"></span>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>RNN is a special kind of MLP that takes its output as input to remember the previous information. It is such an simple struture that it can&#39;t remember as much information as we want. Besides, since RNN updates hidden state recurrently, the cumulative chain of gradients will become rather long, which may result in gradient explosion or gradient vanishing.</p>
<h1 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1406.1078.pdf">Gated Recurrent Unit</a> (GRU) is a method to solve gradient anomaly in RNN. Its idea is based on three facts:</p>
<ul>
<li>Some tokens have nothing to do with previous tokens.</li>
<li>Some tokens are closely related to previous tokens.</li>
<li>Current token may make no sense. It is better to just ignore its influence.</li>
</ul>
<p>Hence, GRU defines two kinds of gate to catch long-term and short-term relationship:</p>
<ul>
<li>Reset Gate $\mathbf{R}_t$, catches short-term relationship between current token and previous tokens:<br>$$\mathbf{R}_t&#x3D;\sigma(\mathbf{X}_t\mathbf{W} _{xr}+\mathbf{H} _{t-1}\mathbf{W} _{hr}+\mathbf{b}_r)$$</li>
<li>Update Gate $\mathbf{Z}_t$, catches long-term relationship between current token and previous tokens:<br>$$\mathbf{Z}_t&#x3D;\sigma(\mathbf{X}_t\mathbf{W} _{xz}+\mathbf{H} _{t-1}\mathbf{W} _{hz}+\mathbf{b}_z)$$</li>
</ul>
<p>Both values of $\mathbf{R}_t$ and $\mathbf{Z}_t$ ($\sigma$ means sigmoid) are between $0$ and $1$. $\mathbf{R}_t$ is used to generate <em>candidate hidden state</em>:</p>
<p>$$\tilde{\mathbf{H}}_t&#x3D;\tanh(\mathbf{X}_t\mathbf{W} _{xh}+(\mathbf{R}_t\odot\mathbf{H} _{t-1})\mathbf{W} _{hh}+\mathbf{b}_h)$$</p>
<p>As its name suggests, reset gate $\mathbf{R}_t$ will weigh the influence of previous tokens $\mathbf{H} _{t-1}$ on current sequence and gather the information of current token and previous tokens. Since $\mathbf{R}_t$ is always smaller than $1$, it pays more attention to current token $\mathbf{X}_t$ while weakens $\mathbf{H} _{t-1}$. That&#39;s why we say that $\mathbf{R}_t$ catches short-term relationship.</p>
<p>After generating the <em>candidate hidden state</em>, update gate $\mathbf{Z}_t$ generates real $\mathbf{H}_t$ from previous sequence $\mathbf{H} _{t-1}$ and current candidate sequence $\tilde{\mathbf{H}}_t$:</p>
<p>$$\mathbf{H}_t&#x3D;\mathbf{Z}_t\odot\mathbf{H} _{t-1}+(1-\mathbf{Z}_t)\odot\tilde{\mathbf{H}}_t$$</p>
<p>When $\mathbf{Z}_t$ is close to $0$, it means that the current token make sense and it may have something to do with previous tokens (based on $\mathbf{R}_t$). On the contrary, when $\mathbf{Z}_t$ is close to $1$, it means that the current token makes no sense. $\mathbf{Z}_t$ weighs $\mathbf{H} _{t-1}$ and $\tilde{\mathbf{H}}_t$. That&#39;s why we say that $\mathbf{Z}_t$ catches long-term relationship. </p>
<p><img src="/2023/05/29/CommonRNNModels/1.png" alt="1"></p>
<center style="font-size:12px; font-weight:bold">Fig. 1. Computing process in GRU</center><br>

<p>Compared with RNN, GRU requires more model parameters ($\mathbf{W} _{xr}$, $\mathbf{W} _{hr}$, $\mathbf{W} _{xz}$, $\mathbf{W} _{hz}$, $\mathbf{W} _{xh}$, $\mathbf{W} _{hh}$ and corresponding bias $\mathbf{b}$). All of them are learnable parameters in one GRU layer. The two gates help the agent properly forget current or previous information. This will shorten the gradient cumulative chain to a certain degree.</p>
<blockquote>
<p><code>nn.GRU</code> is the class of GRU in PyTorch. It is almost the same as <code>nn.RNN</code> though it has more model parameters.</p>
</blockquote>
<h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><p><a target="_blank" rel="noopener" href="https://papers.baulab.info/Hochreiter-1997.pdf">Long-Short-Term Memory</a> (LSTM) is almost the same as GRU but it is more complicated.</p>
<p><img src="/2023/05/29/CommonRNNModels/2.png" alt="2"></p>
<center style="font-size:12px; font-weight:bold">Fig. 2. Computing process in LSTM</center><br>

<p>Compared with GRU, LSTM use memory cell $\mathbf{C}_t$ to record information. The function of $\mathbf{C}_t$ in LSTM is similar as $\mathbf{H}_t$&#39;s in GRU. But $\mathbf{C}_t$ only propagates inside LSTM and the output of LSTM is still $\mathbf{H}_t$. In addition, LSTM takse $\mathbf{Z}_t$ and $(1-\mathbf{Z}_t)$ apart to form forget gate $\mathbf{F}_t$ and input gate $\mathbf{I}_t$:</p>
<p>$$<br>\begin{cases}<br>    \mathbf{F}_t&#x3D;\sigma(\mathbf{X}_t\mathbf{W} _{xf}+\mathbf{H} _{t-1}\mathbf{W} _{hf}+\mathbf{b}_f) \\<br>    \mathbf{I}_t&#x3D;\sigma(\mathbf{X}_t\mathbf{W} _{xi}+\mathbf{H} _{t-1}\mathbf{W} _{hi}+\mathbf{b}_i)<br>\end{cases}<br>$$</p>
<p>Similarly, LSTM use $\tilde{\mathbf{C}}_t$ to record the relationship between current token and previous tokens but it doesn&#39;t reset previous tokens:</p>
<p>$$\tilde{\mathbf{C}}_t&#x3D;\tanh(\mathbf{X}_t\mathbf{W} _{xc}+\mathbf{H} _{t-1}\mathbf{W} _{hc}+\mathbf{b}_c)<br>$$</p>
<p>Then, LSTM generate memory cell $\mathbf{C}_t$ by weighing previous information $\mathbf{C} _{t-1}$ and current information $\tilde{\mathbf{C}}_t$:</p>
<p>$$\mathbf{C}_t&#x3D;\mathbf{F}_t\odot\mathbf{C} _{t-1}+\mathbf{I}_t\odot\tilde{\mathbf{C}}_t$$</p>
<p>Since $\mathbf{F}_t$ and $\mathbf{I}_t$ are no longer relevant. LSTM can combine previous information and current information more flexibly. $\mathbf{C}_t$ only flows inside LSTM. To generate the output, LSTM use output gate $\mathbf{O}_t$ for reset gate $\mathbf{R}_t$:</p>
<p>$$<br>\begin{cases}<br>    \mathbf{O}_t&#x3D;\sigma(\mathbf{X}_t\mathbf{W} _{xo}+\mathbf{H} _{t-1}\mathbf{W} _{ho}+\mathbf{b}_o)\\<br>    \mathbf{H}_t&#x3D;\mathbf{O}_t\odot\tanh(\mathbf{C}_t)<br>\end{cases}<br>$$</p>
<p>where $\tanh$ is to make sure that $\mathbf{H}_t$ is range from $-1$ to $1$ so that the agent can control gradients better.</p>
<blockquote>
<p><code>nn.LSTM</code> is the class of LSTM in PyTorch. It is almost the same as <code>nn.GRU</code>.</p>
</blockquote>
<p>Though LSTM is more complex, GRU performs as well as LSTM.</p>
<h1 id="DRNN"><a href="#DRNN" class="headerlink" title="DRNN"></a>DRNN</h1><p>Deep Recurrent Neural Networks (DRNNs) are neural networks with multiple hidden layers. Their structures are the same as MLP&#39;s.</p>
<h1 id="BRNN"><a href="#BRNN" class="headerlink" title="BRNN"></a>BRNN</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2210.08402.pdf">Bidirectional Recurrent Neural Networks</a> (BRNNs) are neural networks that consider not only the leftward context but also the rightward context. In some scenarios, a token is not only associated with its previous tokens but also its future tokens, for example, contextual analysis and cloze. In this case, it is better for the agent to consider the future tokens in addition to the previous tokens. And that&#39;s what BRNNs does:</p>
<p><img src="/2023/05/29/CommonRNNModels/3.png" alt="3"></p>
<center style="font-size:12px; font-weight:bold">Fig. 3. BRNNs</center><br>

<p>BRNNs assign two independent RNN layers with the same structure to each hidden layer, where one deals with the leftward context and another one deals with the rightward context (just takse the antisequence as input):</p>
<p>$$<br>\begin{cases}<br>    \overrightarrow{\mathbf{H}} _t&#x3D;\text{activation}(\mathbf{X}_t\mathbf{W} _{xh} ^{(f)}+\overrightarrow{\mathbf{H}} _{t-1}\mathbf{W} _{hh} ^{(f)}+\mathbf{b} _h ^{(f)})\\<br>    \overleftarrow{\mathbf{H}} _t&#x3D;\text{activation}(\mathbf{X}_t^r\mathbf{W} _{xh} ^{(b)}+\overleftarrow{\mathbf{H}} _{t-1}\mathbf{W} _{hh} ^{(b)}+\mathbf{b} _h ^{(b)})<br>\end{cases}<br>$$</p>
<p>Then, the concatenation of $\overrightarrow{\mathbf{H}} _t$ and $\overleftarrow{\mathbf{H}} _t$ is passed as output $\mathbf{H} _t&#x3D;(\overrightarrow{\mathbf{H}} _t,\overleftarrow{\mathbf{H}} _t)$ to the next layer.</p>
<p>BRNNs only work when the sequence contains information about future. Hence, BRNNs can&#39;t predict the future. Instead, BRNNs are usually used to <strong>extract features</strong> from a sequence, just like what convolutional layers do.</p>
<blockquote>
<p>There is keyword <code>bidirectional</code> in <code>nn.RNN</code>, <code>nn.GRU</code> and <code>nn.LSTM</code>. To enable BRNN, we can just set <code>bidirectional=True</code>.</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zclzcl0223.github.io/2023/05/29/CommonRNNModels/" data-id="clzik1qt4000om07k5k0r8ya0" data-title="Common RNN Models" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/05/31/EncoderDecoder/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          The Encoder-Decoder Architecture
        
      </div>
    </a>
  
  
    <a href="/2023/05/25/RNN/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">RNN: a Special Kind of MLP</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Advanced-Model/">Advanced Model</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CS7313-Computational-Complexity/">CS7313: Computational Complexity</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Configuration/">Configuration</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Dive-Into-Deep-Learning/">Dive Into Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GNN/">GNN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kernel-Method/">Kernel Method</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MATH6005-Matrix-Theory/">MATH6005: Matrix Theory</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning-by-AndrewNg/">Machine Learning by AndrewNg</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper/">Paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Programming-Language/">Programming Language</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tool/">Tool</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Attention-Mechanism/" rel="tag">Attention Mechanism</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Configuration/" rel="tag">Configuration</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Analysis/" rel="tag">Data Analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dataset-Distillation/" rel="tag">Dataset Distillation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Decision-Trees/" rel="tag">Decision Trees</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GCN/" rel="tag">GCN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GNN/" rel="tag">GNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Generative-AI/" rel="tag">Generative AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/" rel="tag">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lab/" rel="tag">Lab</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markup-Language/" rel="tag">Markup Language</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/" rel="tag">Math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Paper/" rel="tag">Paper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/" rel="tag">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Recommender-System/" rel="tag">Recommender System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reinforcement-Learning/" rel="tag">Reinforcement Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Supervised-Learning/" rel="tag">Supervised Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Theoretical-Computer-Science/" rel="tag">Theoretical Computer Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/" rel="tag">Tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Unsupervised-Learning/" rel="tag">Unsupervised Learning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Attention-Mechanism/" style="font-size: 11.82px;">Attention Mechanism</a> <a href="/tags/CNN/" style="font-size: 12.73px;">CNN</a> <a href="/tags/Configuration/" style="font-size: 10px;">Configuration</a> <a href="/tags/Data-Analysis/" style="font-size: 10px;">Data Analysis</a> <a href="/tags/Dataset-Distillation/" style="font-size: 13.64px;">Dataset Distillation</a> <a href="/tags/Decision-Trees/" style="font-size: 10px;">Decision Trees</a> <a href="/tags/Deep-Learning/" style="font-size: 20px;">Deep Learning</a> <a href="/tags/GCN/" style="font-size: 11.82px;">GCN</a> <a href="/tags/GNN/" style="font-size: 15.45px;">GNN</a> <a href="/tags/Generative-AI/" style="font-size: 10.91px;">Generative AI</a> <a href="/tags/Hexo/" style="font-size: 10.91px;">Hexo</a> <a href="/tags/Lab/" style="font-size: 10.91px;">Lab</a> <a href="/tags/Linux/" style="font-size: 16.36px;">Linux</a> <a href="/tags/Machine-Learning/" style="font-size: 17.27px;">Machine Learning</a> <a href="/tags/Markup-Language/" style="font-size: 10px;">Markup Language</a> <a href="/tags/Math/" style="font-size: 19.09px;">Math</a> <a href="/tags/Paper/" style="font-size: 14.55px;">Paper</a> <a href="/tags/Python/" style="font-size: 18.18px;">Python</a> <a href="/tags/RNN/" style="font-size: 10.91px;">RNN</a> <a href="/tags/Recommender-System/" style="font-size: 10.91px;">Recommender System</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 10.91px;">Reinforcement Learning</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/Supervised-Learning/" style="font-size: 11.82px;">Supervised Learning</a> <a href="/tags/Theoretical-Computer-Science/" style="font-size: 15.45px;">Theoretical Computer Science</a> <a href="/tags/Tool/" style="font-size: 18.18px;">Tool</a> <a href="/tags/Unsupervised-Learning/" style="font-size: 11.82px;">Unsupervised Learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/06/17/Diffusion/">Diffusion</a>
          </li>
        
          <li>
            <a href="/2024/01/20/VAE/">VAE</a>
          </li>
        
          <li>
            <a href="/2023/12/02/CountingComplexity/">Computational Complexity: Complexity of Counting</a>
          </li>
        
          <li>
            <a href="/2023/11/24/MatrixTheory5/">MatrixTheory: 特殊矩阵与矩阵分解</a>
          </li>
        
          <li>
            <a href="/2023/11/13/RandomizedComputation/">Computational Complexity: Randomized Computation</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 ChaosTsang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/" class="mobile-nav-link">home</a>
  
    <a href="/about/" class="mobile-nav-link">about</a>
  
    <a href="/tags/" class="mobile-nav-link">tags</a>
  
    <a href="/categories/" class="mobile-nav-link">categories</a>
  
    <a href="/archives/" class="mobile-nav-link">archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>





<script src="/js/script.js"></script>





  </div>
</body>
</html>